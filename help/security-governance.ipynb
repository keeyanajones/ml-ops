{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Security and Governance\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/batch-prediction/intro_batch_prediction.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/batch-prediction/intro_batch_prediction.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/batch-prediction/intro_batch_prediction.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Keeyana Jones](https://github.com/keeyanajones)|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## I. Identity and Access Management (IAM) in MLOps\n",
        "\n",
        "IAM is the cornerstone of security in any cloud environment, and MLOps is no exception. It defines who can do what, where, and when. In MLOps, this complexity increases due to the diverse roles (data scientists, ML engineers, data engineers, ops), the different types of resources (data, models, compute, pipelines), and the various stages of the ML lifecycle.\n",
        "\n",
        "Key Principles:\n",
        "\n",
        "- Principle of Least Privilege (PoLP): Grant users and service accounts only the permissions absolutely necessary to perform their tasks, and nothing more. This minimizes the blast radius in case of a breach.\n",
        "\n",
        "- Segregation of Duties (SoD): Separate critical functions so that no single individual has control over an entire process. For example, the person who trains a model shouldn't necessarily be the only one who can deploy it to production.\n",
        "\n",
        "GCP IAM Best Practices for MLOps:\n",
        "\n",
        "- Custom Roles over Predefined Roles: While GCP offers many predefined roles (e.g., roles/aiplatform.admin, roles/bigquery.dataViewer), these often grant more permissions than needed. Create custom roles with granular permissions tailored to specific tasks (e.g., a \"Vertex AI Model Deployer\" role with aiplatform.models.deploy permission but no training permissions).\n",
        "\n",
        "   Example for Vertex AI:\n",
        "   - Data Scientist: aiplatform.user (or a custom role allowing training, experiment tracking, notebook access)\n",
        "   - ML Engineer: Custom role with permissions to create/update Vertex AI Pipelines, manage Model Registry, deploy endpoints (aiplatform.endpoints.deploy, aiplatform.models.upload).\n",
        "\n",
        "Data Engineer: bigquery.dataEditor, storage.objectAdmin for data buckets, dataflow.admin (if using Dataflow).\n",
        "\n",
        "   - Read-only Access: A \"Vertex AI Model Viewer\" role for business users to monitor deployed models or view experiment results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Service Accounts for Automation:\n",
        "\n",
        "   - Dedicated Service Accounts: Create separate service accounts for different automated processes (e.g., one for training pipelines, one for deployment pipelines, one for model monitoring jobs).\n",
        "\n",
        "- Workload Identity (GKE/Cloud Run): If running ML workloads on GKE or Cloud Run, use Workload Identity to securely bind Kubernetes service accounts to GCP service accounts, removing the need to manage secret keys.\n",
        "- Vertex AI Service Agent: Vertex AI uses a Google-managed service account (the \"Vertex AI Service Agent\") to interact with other GCP services on your behalf (e.g., reading data from Cloud Storage for training). Ensure this service agent has the necessary permissions on your resources.\n",
        "\n",
        "Resource Hierarchy and IAM Policies:\n",
        "\n",
        "   - Organize your GCP resources using Folders and Projects to align with your organizational structure and apply IAM policies at appropriate levels. Policies at the folder level inherit to projects and resources within them.\n",
        "\n",
        "   - Project-level vs. Resource-level Access: Granting access at the project level is easier for broad access, but resource-level access (e.g., allowing a service account to only predict on a specific Vertex AI endpoint) is more granular for sensitive production systems.\n",
        "\n",
        "Regular Audits and Review:\n",
        "\n",
        "   - Periodically review IAM policies to ensure they still adhere to PoLP and that no unnecessary permissions have accumulated. Use GCP's Policy Analyzer and Recommender services.\n",
        "\n",
        "Leverage Cloud Audit Logs to track who accessed what and when, providing a crucial trail for security investigations.\n",
        "\n",
        "   - Strong Authentication: Enforce Multi-Factor Authentication (MFA) for all user accounts, especially those with administrative privileges.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## II. Data Residency in MLOps\n",
        "\n",
        "Data residency refers to the physical location where data is stored and processed. This is a critical concern due to legal and regulatory requirements (e.g., GDPR, HIPAA, country-specific data sovereignty laws).\n",
        "\n",
        "Challenges in MLOps:\n",
        "\n",
        "- Global Infrastructure vs. Local Laws: Cloud providers like GCP have global infrastructure, but many regulations require data to stay within specific geographical boundaries (e.g., EU data must remain in the EU).\n",
        "- Training Data vs. Inference Data: Data used for training models (often large historical datasets) and data used for real-time inference (live user data) both fall under residency rules.\n",
        "- Model Artifacts: The trained models themselves, and their metadata, can contain sensitive information or be derived from sensitive data, thus potentially falling under data residency requirements.\n",
        "- Generative AI Nuances: With foundation models like Gemini, understanding where your prompts and outputs are processed and stored is crucial.\n",
        "\n",
        "GCP Solutions and Best Practices:\n",
        "\n",
        "   - Regional Selection:\n",
        "       - Choose the Right Region: When provisioning GCP resources (Vertex AI, Cloud Storage, BigQuery, Compute Engine, GKE), always select the region(s) that meet your data residency requirements.\n",
        "       - Multi-Region vs. Single Region: Understand the difference. Multi-region (e.g., europe-west) means data is replicated across multiple data centers within that multi-region, providing higher availability but still adhering to the broader geographical boundary.\n",
        "   - Vertex AI and Data Residency:\n",
        "       - Managed Services: Vertex AI services (Training, Prediction Endpoints, Feature Store, Pipelines) are regional. When you create resources in a specific region, Google commits to processing your data within that region.\n",
        "       - Generative AI on Vertex AI (Gemini): Google provides commitments for data residency during ML processing for Gemini models in specific regions (e.g., Canada, Europe, US). This means your prompts and the model's processing for inference will stay within your chosen region.\n",
        "\n",
        "- Data Caching for Gemini: By default, Gemini models on Vertex AI may cache inputs for up to 24 hours to reduce latency. For strict data residency, you must explicitly disable this caching at the project level. Google provides API calls to manage this.\n",
        "- Customer-Managed Encryption Keys (CMEK): For enhanced control, use CMEK to encrypt your data in Vertex AI, Cloud Storage, and BigQuery. You manage the encryption keys in Cloud Key Management Service (Cloud KMS), providing an extra layer of control over your data's security.\n",
        "\n",
        "- Data Storage (Cloud Storage, BigQuery): Configure buckets and datasets to be in the required regions. Implement lifecycle policies to manage data retention, ensuring data doesn't linger unnecessarily.\n",
        "- Hybrid Cloud/Edge Solutions: For extremely strict low-latency or on-premises processing requirements, consider hybrid solutions where some ML inference or data pre-processing occurs on-premises or at the edge, while model training might happen in the cloud.\n",
        "\n",
        "- Documentation: Clearly document your data flows, storage locations, and processing regions for all ML workloads to demonstrate compliance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## III. Compliance in MLOps\n",
        "\n",
        "Compliance involves adhering to relevant laws, regulations, industry standards, and internal policies. For MLOps, this extends beyond general data privacy to AI-specific regulations.\n",
        "\n",
        "Key Compliance Areas:\n",
        "\n",
        "   - Data Privacy Regulations:\n",
        "    - GDPR (Europe), CCPA/CPRA (California), HIPAA (Healthcare, US), LGPD (Brazil), PIPL (China): These regulations govern how personal data is collected, stored, processed, and used.\n",
        "    - Impact on ML: Requires anonymization/pseudonymization of data, consent management, data minimization, right to erasure, and data portability.\n",
        "    - GCP Tools:\n",
        "       - Sensitive Data Protection: Detects and redacts/masks PII/PHI in data before it's used for training or processed by LLMs.\n",
        "\n",
        "Cloud Data Loss Prevention (DLP): Automates the identification and protection of sensitive data across your GCP environment.\n",
        "\n",
        "- IAM & Audit Logs: Ensure access control and traceability for sensitive data.\n",
        "\n",
        "AI-Specific Regulations:\n",
        "\n",
        "- EU AI Act: A landmark regulation that categorizes AI systems by risk level and imposes stringent requirements for high-risk AI (e.g., conformity assessments, risk management systems, human oversight, transparency, robustness).\n",
        "- NIST AI Risk Management Framework: A voluntary framework providing guidance on managing AI risks, including bias, privacy, and security.\n",
        "- Ethical AI Principles: Increasingly, organizations are adopting formal ethical AI principles that become internal compliance standards.\n",
        "\n",
        "Industry-Specific Certifications:\n",
        "\n",
        "- ISO 27001 (Information Security Management), ISO 27017 (Cloud Security), ISO 27018 (Cloud Privacy), SOC 1/2/3: - These certifications demonstrate adherence to best practices for security and privacy.\n",
        "- HIPAA (Health Insurance Portability and Accountability Act): For healthcare data. GCP has a BAA (Business Associate Addendum) with customers to support HIPAA compliance.\n",
        "\n",
        "GCP Support for Compliance:\n",
        "\n",
        "-  Google Cloud Compliance Offerings: Google Cloud regularly undergoes independent verification of its security, privacy, and compliance controls. Check the Google Cloud Compliance page for a comprehensive list of certifications (ISO, SOC, HIPAA, FedRAMP, etc.).\n",
        "\n",
        "- Assured Workloads: For highly regulated industries, Assured Workloads helps meet compliance requirements by enforcing specific controls on data location, personnel access, and support processes.\n",
        "- VPC Service Controls: Creates security perimeters around your sensitive data and services, dramatically reducing the risk of data exfiltration. Essential for high-risk ML workloads.\n",
        "- Access Transparency: Provides visibility into Google administrative access to your data, offering logs of actions taken by Google staff.\n",
        "- Data Governance & Generative AI on Vertex AI: As mentioned in the previous discussion, Google commits to not using your data to train foundation models without explicit permission. You can disable caching for Gemini inputs to achieve zero data retention for prompts.\n",
        "\n",
        "- Building a Compliance Framework for MLOps:\n",
        "\n",
        "    - Risk Assessment: Identify potential risks (e.g., bias, data leakage, PII exposure, model misuse) at each stage of your ML pipeline.\n",
        "    - Policy Definition: Translate external regulations and internal ethical principles into concrete internal policies for data handling, model development, deployment, and monitoring.\n",
        "    - Tooling & Automation: Implement GCP services and MLOps tools to enforce policies (e.g., IAM, DLP, Vertex AI Model Monitoring).\n",
        "    - Auditing & Reporting: Maintain detailed audit trails (Cloud Audit Logs, Vertex AI Metadata) and generate reports to demonstrate compliance to auditors.\n",
        "\n",
        "- Training & Awareness: Ensure all personnel involved in MLOps (data scientists, engineers, product managers) are trained on relevant security, privacy, and compliance requirements.\n",
        "\n",
        "    - Continuous Monitoring: Compliance is not a one-time event. Continuously monitor your systems, processes, and model behaviors to ensure ongoing adherence.\n",
        "\n",
        "By proactively integrating IAM, data residency considerations, and a robust compliance framework into your MLOps strategy, you can build and deploy AI systems responsibly, mitigate risks, and gain the trust of your users and stakeholders."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_batch_prediction.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
