{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# MLOps Challenges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Keeyana Jones](https://github.com/keeyanajones)|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        " MLOps professionals working with GCP's AI services are at the forefront of a dynamic field. They face a unique blend of technical, data-centric, and organizational challenges, demanding a holistic skill set and a commitment to continuous learning and adaptation.\n",
        "\n",
        "### 1. Data Stewardship and Governance\n",
        "\n",
        "This is perhaps the foundational challenge, and it only gets amplified with the scale and complexity of data used by Vertex AI, Vision AI, and Gemini.\n",
        "\n",
        "* **Data Lineage and Versioning:** Knowing exactly where every piece of data came from, how it was transformed, and which version of the data was used to train a specific model is crucial for reproducibility and debugging. With large datasets and continuous pipelines on GCP, tracking this manually is impossible. Vertex AI Metadata and Feature Store help, but ensuring consistent adoption and best practices across teams is tough.\n",
        "* **Data Quality and Consistency:** Garbage in, garbage out. Ensuring high-quality, consistent data across various sources (BigQuery, Cloud Storage, etc.) for training and inference is paramount. This includes addressing missing values, outliers, data type mismatches, and schema evolution. With Vision AI and Gemini, this extends to managing the quality of images, videos, audio, and vast text corpora.\n",
        "* **Data Privacy and Security (Compliance):** Working with sensitive data (e.g., in healthcare with Vision AI for medical imaging, or personal data with Gemini for customer interactions) requires strict adherence to regulations like GDPR, HIPAA, and others. Implementing robust access controls, encryption, anonymization, and auditing on GCP is a continuous effort.\n",
        "* **Feature Store Management:** While Vertex AI Feature Store offers a centralized repository for features, managing the lifecycle of features (creation, versioning, serving, deprecation) and ensuring their consistency across training and serving environments can be complex, especially with a growing number of models and teams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Concept Drift and Model Monitoring\n",
        "\n",
        "This is where the \"Ops\" in MLOps truly comes into play, and it's a constant battle with the dynamic nature of real-world data.\n",
        "\n",
        "- Detecting and Quantifying Drift (Data and Concept):\n",
        "    * **Data Drift:** Changes in the distribution of input data over time (e.g., user demographics shift, product trends change).\n",
        "    * **Concept Drift:** Changes in the relationship between input features and the target variable (e.g., what constitutes \"fraud\" evolves, customer preferences for recommendations change). Detecting these, especially for complex, multimodal models like those powered by Vision AI and Gemini, can be incredibly challenging. How do you quantify \"drift\" in embeddings generated by large language models, or in nuanced visual features?\n",
        "    * **Lack of Ground Truth in Real-Time:** Often, obtaining immediate ground truth labels for production predictions is difficult or impossible. This makes it hard to directly measure model accuracy in real-time and pinpoint exactly when and why performance is degrading.\n",
        "    * **Setting Effective Alerting Thresholds:** Deciding what level of drift or performance degradation warrants an alert and triggers retraining is non-trivial. Too sensitive, and you get alert fatigue; too lenient, and your models silently degrade.\n",
        "    * **Automated Retraining and Deployment Strategies:** Once drift is detected, automatically retraining models on fresh data and seamlessly deploying the new versions requires robust CI/CD pipelines, which Vertex AI Pipelines facilitates, but still demands careful design and testing. For Vision and Gemini models, retraining can be computationally expensive and time-consuming.\n",
        "    * **Explainability of Drift:** Understanding why a model is drifting (e.g., is it a new external event, a change in user behavior, or a data pipeline issue?) is crucial for effective remediation, but often difficult to ascertain.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Debugging Complex ML Systems\n",
        "\n",
        "Debugging is notoriously harder in ML than traditional software, and the advanced nature of GCP's AI services adds layers of complexity.\n",
        "\n",
        "* **Black-Box Models (especially deep learning and foundation models):** Gemini and many Vision AI models are \"black boxes.\" It's incredibly difficult to understand why they made a particular prediction, let alone why a specific bug occurred. Debugging often involves analyzing inputs and outputs, rather than stepping through interpretable code logic.\n",
        "* **Non-Determinism and Reproducibility:** ML models, especially those using randomness in training (e.g., dropout, weight initialization), can be non-deterministic. Reproducing a specific error can be incredibly difficult, making debugging a nightmare. Ensuring reproducibility of environments (libraries, versions), data, and model states is a constant battle.\n",
        "* **Data-Dependent Bugs:** Errors often aren't in the code itself, but in the data. A subtle bias in the training data, an unexpected edge case in production data, or a data corruption issue can lead to silent failures or incorrect predictions that are hard to trace.\n",
        "* **Distributed Systems and Pipelines:** Vertex AI Pipelines orchestrates multiple steps and services. Debugging issues that span across data ingestion, feature engineering, model training, deployment, and serving environments requires distributed logging, tracing, and monitoring tools to pinpoint the exact failure point.\n",
        "* **Resource Management and Performance Debugging:** ML workloads, especially with large models, are resource-intensive. Debugging performance bottlenecks, memory leaks, or inefficient resource utilization (e.g., GPU/TPU usage) across a distributed GCP environment can be a specialized skill.\n",
        "* **Prompt Engineering and Model Behavior Debugging (for Gemini/LLMs):** With generative AI, debugging extends to prompt engineering. Why did Gemini generate a nonsensical response? Was it the prompt, the model's training data, or a subtle issue in the inference pipeline? This requires understanding model biases, safety filters, and the nuances of prompt design.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## General Challenges for Professionals in MLOps with GCP AI:\n",
        "\n",
        "- **Skill Gap:** The MLOps landscape is rapidly evolving. Professionals need a blend of data science, software engineering, and operations skills, along with deep expertise in GCP-specific services (Vertex AI, BigQuery, GCS, Kubernetes Engine, etc.). Keeping up with the pace of innovation (e.g., new Gemini models, Vertex AI features) is a continuous challenge.\n",
        "- **Tooling Proliferation and Integration:** While GCP offers a comprehensive suite, stitching together various tools (e.g., custom logging with Cloud Logging, specialized monitoring tools with Vertex AI Monitoring, third-party libraries) and ensuring seamless integration can be complex.\n",
        "- **Cost Management:** Running and scaling ML workloads, especially with large models and extensive data processing, can become very expensive. Optimizing costs on GCP while maintaining performance is a constant balancing act.\n",
        "- **Organizational Alignment and Collaboration:** Bridging the gap between data scientists, ML engineers, and IT operations teams remains a significant challenge. Ensuring everyone speaks the same language, understands each other's priorities, and collaborates effectively is crucial for MLOps success.\n",
        "- **Ethical AI and Bias:** Ensuring fairness, transparency, and accountability in ML models, especially those used in sensitive applications, is a growing concern. Detecting and mitigating bias in data and models (e.g., in Vision AI for facial recognition or Gemini for text generation) adds another layer of complexity to MLOps.\n",
        "\n",
        "To learn more, see the [MLOps Challenges](https://cloud.google.com/vertex-ai/generative-ai/docs) page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objectives\n",
        "\n",
        "In this tutorial, you learn how to handle common challenges with the Gemini API in Vertex AI. This tutorial shows how to use **Google Cloud Resources**, **Gemini** and **Vertex AI** when faced with challenges. \n",
        "\n",
        "You will complete the following tasks:\n",
        "\n",
        "1. Data Stewardship and Governance\n",
        "2. Concept Drift and Model Monitoring\n",
        "3. Debugging Complex ML Systems\n",
        "4. Skill Gap\n",
        "5. Tooling Proliferation and Integration\n",
        "6. Cost Management\n",
        "7. Organizational Alignment and Collaboration\n",
        "8. Ethical AI and Bias\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Google Gen AI SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet google-genai pandas google-cloud-storage google-cloud-bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06489bd14f16"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe00fa0b8bb7"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "from google import genai\n",
        "from google.cloud import bigquery\n",
        "from google.genai.types import CreateBatchJobConfig\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and create client\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfca4d7bd6db"
      },
      "outputs": [],
      "source": [
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e43229f3ad4f"
      },
      "source": [
        "### Load model\n",
        "\n",
        "You can find a list of the Gemini models that support batch predictions in the [Multimodal models that support batch predictions](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-gemini#multimodal_models_that_support_batch_predictions) page.\n",
        "\n",
        "This tutorial uses Gemini 2.0 Flash (`gemini-2.0-flash-001`) model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf93d5f0ce00"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash-001\"  # @param {type:\"string\", isTemplate: true}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "265f180b58e0"
      },
      "source": [
        "## 1. Data Stewardship and Governance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What is Data Stewardship and Governance?\n",
        "\n",
        "In the context of MLOps, Data Stewardship and Governance refer to the set of policies, processes, roles, and technologies that ensure the responsible and effective management of data throughout its entire lifecycle. This isn't just about storing data; it's about making sure the right people can access the right data, at the right time, in the right quality, and for the right purpose, all while adhering to legal and ethical guidelines.\n",
        "\n",
        "Here's a deeper dive into its key components:\n",
        "- **Data Quality**:\n",
        "    - **Accuracy**: Is the data correct and truthful?\n",
        "    - **Completeness**: Are there missing values or records?\n",
        "    - **Consistency**: Is the data uniform across different systems and time points?\n",
        "    - **Timeliness**: Is the data up-to-date and available when needed?\n",
        "    - **Validity**: Does the data conform to defined formats, types, and ranges?\n",
        "    - **Uniqueness**: Are there duplicate records?\n",
        "    - **Relevance**: Is the data actually useful for the intended ML task?\n",
        "\n",
        "- **Data Lineage and Provenance**:\n",
        "    - Tracking the entire journey of data from its source to its final use in a model. This includes:\n",
        "        - Where did the raw data come from? (e.g., BigQuery table, GCS bucket, external API)\n",
        "        - What transformations were applied to it? (e.g., aggregations, joins, feature engineering steps in Vertex AI Pipelines)\n",
        "        - Which version of the data was used for a specific model training run?\n",
        "        - Who accessed or modified the data and when?\n",
        "    - Crucial for debugging, auditing, reproducibility, and understanding model behavior.\n",
        "\n",
        "- **Data Versioning**:\n",
        "    - Managing different versions of datasets, similar to how code is versioned with Git.\n",
        "    - Allows for rollback to previous states, experimentation with different data versions, and ensuring that a  specific model can always be re-trained with the exact data it originally saw. While Git isn't ideal for large datasets, tools like DVC (Data Version Control) or specialized data lakehouse solutions (like those built on Apache Iceberg, which Dremio offers \"Git-for-Data\" capabilities for) are designed for this.\n",
        "\n",
        "- **Metadata Management**:\n",
        "    - Creating and maintaining \"data about data.\" This includes:\n",
        "        - **Technical metadata:** Schema definitions, data types, storage locations, transformation logic.\n",
        "        - **Business metadata:** Descriptions of data fields, definitions of metrics, ownership, purpose, sensitivity level.\n",
        "        - **Operational metadata:** Last updated time, refresh frequency, pipeline run IDs.\n",
        "    - A robust metadata catalog (like Data Catalog on GCP, or open-source tools like Amundsen or DataHub) makes data discoverable, understandable, and trustable for data scientists and engineers.\n",
        "\n",
        "- **Data Privacy and Security**:\n",
        "    - Implementing controls to protect sensitive data (e.g., PII, PHI) from unauthorized access, use, or disclosure.\n",
        "    - Ensuring compliance with regulations (GDPR, HIPAA, CCPA, etc.) through anonymization, encryption, access controls (IAM on GCP), and data retention policies.\n",
        "    - Especially critical for models dealing with personal or regulated information, like Vision AI for medical images or Gemini for customer interactions.\n",
        "\n",
        "- **Roles and Responsibilities (Data Stewardship)**:\n",
        "    - Defining who owns the data, who is responsible for its quality, who can access it, and who approves changes.\n",
        "    - Data Stewards are key individuals or teams responsible for the practical implementation of data governance policies within their domain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why is it so Challenging in MLOps (especially with GCP AI)?\n",
        "\n",
        "- **Dynamic Data:** Unlike traditional software, ML models constantly consume new data, which changes over time (concept/data drift). This makes quality, lineage, and versioning a moving target.\n",
        "- **Scale and Variety:** ML often deals with vast volumes and diverse types of data (structured, unstructured, images, text, audio) from many sources, making governance complex.\n",
        "- **Pipeline Complexity:** ML pipelines are multi-stage, involving data ingestion, preprocessing, feature engineering, training, evaluation, and deployment. Tracking data through all these transformations is hard.\n",
        "- **\"Black Box\" Models:** Advanced models (like Gemini) can be opaque. If a model performs poorly, understanding if it's a data quality issue, a training artifact, or concept drift requires solid data governance to trace back.\n",
        "- **Cross-Functional Teams:** MLOps involves data scientists, ML engineers, data engineers, and ops teams. Ensuring consistent data practices across these diverse roles is a significant coordination effort.\n",
        "- **Evolving Regulations:** Data privacy and AI ethics regulations are constantly changing, demanding agile and adaptable governance frameworks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This example focuses on a basic data quality check and a simple metadata/lineage logging approach within a Jupyter Notebook. For a full-fledged MLOps pipeline, you'd integrate with dedicated metadata stores (like Vertex AI Metadata) and data versioning tools (like DVC).\n",
        "\n",
        "**Scenario:** You're preparing a CSV dataset for a model that predicts customer churn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming you're in a Jupyter Notebook on Google Colab or a local Jupyter env with gcloud auth\n",
        "# If on Google Colab, you might need:\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "# !pip install pandas google-cloud-storage google-cloud-bigquery\n",
        "# !pip install great_expectations # For more robust data quality\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import hashlib\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# --- Configuration for your GCP Project (replace with your actual values) ---\n",
        "GCP_PROJECT_ID = \"your-gcp-project-id\"\n",
        "GCS_BUCKET_NAME = \"your-gdata-bucket\" # e.g., 'ml-data-lake-myproject'\n",
        "BIGQUERY_DATASET = \"your_ml_dataset\" # e.g., 'customer_churn_data'\n",
        "BIGQUERY_TABLE = \"raw_customer_data_v1\"\n",
        "\n",
        "# Set up basic logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "print(f\"--- Starting Data Stewardship Example for Project: {GCP_PROJECT_ID} ---\")\n",
        "\n",
        "# --- Step 1: Simulate Data Ingestion (e.g., from a CSV, could be BigQuery/GCS) ---\n",
        "# Create a dummy CSV file for demonstration\n",
        "data = {\n",
        "    'customer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'age': [30, 45, 22, 58, 35, 41, 29, 50, None, 33],\n",
        "    'monthly_charges': [50.0, 75.5, 30.2, 90.1, 62.8, 88.0, 45.3, 70.9, 105.0, 55.7],\n",
        "    'has_churned': [0, 1, 0, 1, 0, 1, 0, 1, 1, 0],\n",
        "    'contract_type': ['Month-to-month', 'Two year', 'Month-to-month', 'One year', 'Month-to-month', 'Two year', 'Month-to-month', 'One year', 'Two year', 'Month-to-month'],\n",
        "    'data_source': ['CRM', 'Website', 'CRM', 'CRM', 'Website', 'Website', 'CRM', 'Website', 'CRM', 'Website'],\n",
        "    'ingestion_date': ['2024-01-15', '2024-01-16', '2024-01-15', '2024-01-17', '2024-01-16', '2024-01-17', '2024-01-15', '2024-01-16', '2024-01-17', '2024-01-15']\n",
        "}\n",
        "df_raw = pd.DataFrame(data)\n",
        "# Introduce a subtle data quality issue: a duplicate and an invalid age\n",
        "df_raw.loc[10] = [1, 30, 50.0, 0, 'Month-to-month', 'CRM', '2024-01-18'] # Duplicate customer_id\n",
        "df_raw.loc[11] = [11, 150, 60.0, 0, 'Month-to-month', 'CRM', '2024-01-18'] # Invalid age (too high)\n",
        "\n",
        "raw_data_path = 'local_raw_customer_data.csv'\n",
        "df_raw.to_csv(raw_data_path, index=False)\n",
        "logging.info(f\"Simulated raw data saved to: {raw_data_path}\")\n",
        "\n",
        "# --- Step 2: Data Quality Checks (using Pandas for simplicity) ---\n",
        "\n",
        "def run_data_quality_checks(dataframe, source_name=\"Unknown Source\"):\n",
        "    \"\"\"\n",
        "    Performs basic data quality checks on a pandas DataFrame.\n",
        "    Returns a dictionary of quality metrics and issues.\n",
        "    \"\"\"\n",
        "    quality_report = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'source': source_name,\n",
        "        'row_count': len(dataframe),\n",
        "        'column_count': len(dataframe.columns),\n",
        "        'issues_found': []\n",
        "    }\n",
        "\n",
        "    # Check for missing values\n",
        "    missing_values = dataframe.isnull().sum()\n",
        "    for col, count in missing_values.items():\n",
        "        if count > 0:\n",
        "            quality_report['issues_found'].append(f\"Column '{col}' has {count} missing values.\")\n",
        "            logging.warning(f\"DQ Issue: Column '{col}' has {count} missing values.\")\n",
        "\n",
        "    # Check for duplicate customer_ids\n",
        "    if 'customer_id' in dataframe.columns:\n",
        "        duplicate_ids = dataframe[dataframe.duplicated(subset=['customer_id'], keep=False)]\n",
        "        if not duplicate_ids.empty:\n",
        "            quality_report['issues_found'].append(f\"Found {len(duplicate_ids)} duplicate 'customer_id' entries.\")\n",
        "            logging.warning(f\"DQ Issue: Found {len(duplicate_ids)} duplicate 'customer_id' entries.\")\n",
        "\n",
        "    # Check for invalid age range (e.g., age > 100)\n",
        "    if 'age' in dataframe.columns:\n",
        "        invalid_ages = dataframe[dataframe['age'] > 100]\n",
        "        if not invalid_ages.empty:\n",
        "            quality_report['issues_found'].append(f\"Found {len(invalid_ages)} invalid 'age' values (>100).\")\n",
        "            logging.warning(f\"DQ Issue: Found {len(invalid_ages)} invalid 'age' values (>100).\")\n",
        "\n",
        "    # Check for expected column types (simple check)\n",
        "    expected_types = {\n",
        "        'customer_id': 'int64',\n",
        "        'age': 'float64', # or int64, depending on how NaNs are handled\n",
        "        'monthly_charges': 'float64',\n",
        "        'has_churned': 'int64',\n",
        "        'contract_type': 'object',\n",
        "        'data_source': 'object',\n",
        "        'ingestion_date': 'object' # will convert to datetime later\n",
        "    }\n",
        "    for col, expected_type in expected_types.items():\n",
        "        if col in dataframe.columns and str(dataframe[col].dtype) != expected_type:\n",
        "             quality_report['issues_found'].append(f\"Column '{col}' has unexpected type: {dataframe[col].dtype}, expected {expected_type}.\")\n",
        "             logging.warning(f\"DQ Issue: Column '{col}' has unexpected type: {dataframe[col].dtype}, expected {expected_type}.\")\n",
        "\n",
        "\n",
        "    logging.info(f\"Data quality checks completed for {source_name}. Issues: {len(quality_report['issues_found'])}\")\n",
        "    return quality_report\n",
        "\n",
        "dq_report_raw = run_data_quality_checks(df_raw, source_name=\"Raw Customer Data\")\n",
        "print(\"\\n--- Raw Data Quality Report ---\")\n",
        "print(json.dumps(dq_report_raw, indent=2))\n",
        "\n",
        "# --- Step 3: Data Transformation (e.g., handling missing values, type conversion) ---\n",
        "# Create a copy to perform transformations\n",
        "df_processed = df_raw.copy()\n",
        "\n",
        "# Handle missing 'age' by imputation (e.g., median)\n",
        "df_processed['age'].fillna(df_processed['age'].median(), inplace=True)\n",
        "logging.info(\"Missing 'age' values imputed with median.\")\n",
        "\n",
        "# Convert 'ingestion_date' to datetime\n",
        "df_processed['ingestion_date'] = pd.to_datetime(df_processed['ingestion_date'])\n",
        "logging.info(\"Converted 'ingestion_date' to datetime.\")\n",
        "\n",
        "# Remove duplicates based on 'customer_id' (keeping the first entry)\n",
        "initial_rows = len(df_processed)\n",
        "df_processed.drop_duplicates(subset=['customer_id'], keep='first', inplace=True)\n",
        "logging.info(f\"Removed {initial_rows - len(df_processed)} duplicate 'customer_id' entries.\")\n",
        "\n",
        "# Filter out invalid ages (e.g., > 100)\n",
        "initial_rows = len(df_processed)\n",
        "df_processed = df_processed[df_processed['age'] <= 100]\n",
        "logging.info(f\"Filtered out {initial_rows - len(df_processed)} rows with invalid 'age' (>100).\")\n",
        "\n",
        "processed_data_path = 'local_processed_customer_data.csv'\n",
        "df_processed.to_csv(processed_data_path, index=False)\n",
        "logging.info(f\"Processed data saved to: {processed_data_path}\")\n",
        "\n",
        "\n",
        "# --- Step 4: Data Quality Checks on Processed Data ---\n",
        "dq_report_processed = run_data_quality_checks(df_processed, source_name=\"Processed Customer Data\")\n",
        "print(\"\\n--- Processed Data Quality Report ---\")\n",
        "print(json.dumps(dq_report_processed, indent=2))\n",
        "\n",
        "# --- Step 5: Simple Metadata & Lineage Logging ---\n",
        "# This is a very basic, file-based logging. In production, you'd use a dedicated metadata store.\n",
        "\n",
        "def log_data_artifact_metadata(\n",
        "    artifact_name,\n",
        "    artifact_path,\n",
        "    description,\n",
        "    data_quality_report,\n",
        "    upstream_artifacts=None, # List of (name, path) tuples for lineage\n",
        "    processing_steps_description=\"\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Logs metadata for a data artifact.\n",
        "    \"\"\"\n",
        "    metadata = {\n",
        "        'artifact_name': artifact_name,\n",
        "        'path': artifact_path,\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'description': description,\n",
        "        'file_hash': hashlib.md5(open(artifact_path, 'rb').read()).hexdigest(),\n",
        "        'row_count': pd.read_csv(artifact_path).shape[0],\n",
        "        'column_count': pd.read_csv(artifact_path).shape[1],\n",
        "        'data_quality_summary': data_quality_report,\n",
        "        'upstream_dependencies': upstream_artifacts if upstream_artifacts else [],\n",
        "        'processing_steps': processing_steps_description,\n",
        "        'generated_by_script': os.path.basename(__file__) # Or a unique identifier for this notebook\n",
        "    }\n",
        "    metadata_filename = f\"metadata_{artifact_name.replace(' ', '_').lower()}.json\"\n",
        "    with open(metadata_filename, 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "    logging.info(f\"Metadata for '{artifact_name}' logged to {metadata_filename}\")\n",
        "    return metadata_filename\n",
        "\n",
        "# Log metadata for raw data\n",
        "raw_metadata_file = log_data_artifact_metadata(\n",
        "    artifact_name=\"Raw Customer Data\",\n",
        "    artifact_path=raw_data_path,\n",
        "    description=\"Original customer data from CRM and Website sources, before any cleaning.\",\n",
        "    data_quality_report=dq_report_raw\n",
        ")\n",
        "\n",
        "# Log metadata for processed data, linking to raw data for lineage\n",
        "processed_metadata_file = log_data_artifact_metadata(\n",
        "    artifact_name=\"Processed Customer Data\",\n",
        "    artifact_path=processed_data_path,\n",
        "    description=\"Cleaned and preprocessed customer data, ready for feature engineering or model training.\",\n",
        "    data_quality_report=dq_report_processed,\n",
        "    upstream_artifacts=[\n",
        "        {\"name\": \"Raw Customer Data\", \"path\": raw_data_path, \"metadata_file\": raw_metadata_file}\n",
        "    ],\n",
        "    processing_steps_description=\"Filled missing 'age' with median, converted 'ingestion_date' to datetime, removed duplicate 'customer_id' entries (keeping first), filtered out 'age' > 100.\"\n",
        ")\n",
        "\n",
        "print(\"\\n--- Data Artifact Metadata Logs ---\")\n",
        "with open(raw_metadata_file, 'r') as f:\n",
        "    print(f\"Raw Data Metadata:\\n{f.read()}\")\n",
        "with open(processed_metadata_file, 'r') as f:\n",
        "    print(f\"Processed Data Metadata:\\n{f.read()}\")\n",
        "\n",
        "# --- Template Snippet for BigQuery/GCS Integration (Conceptual) ---\n",
        "# This part would typically be integrated into a more robust pipeline or a separate script.\n",
        "# It demonstrates where you'd use GCP clients.\n",
        "\n",
        "from google.cloud import storage, bigquery\n",
        "\n",
        "# Initialize clients (if not already authenticated)\n",
        "storage_client = storage.Client(project=GCP_PROJECT_ID)\n",
        "bigquery_client = bigquery.Client(project=GCP_PROJECT_ID)\n",
        "\n",
        "# --- Uploading to GCS (for raw data) ---\n",
        "try:\n",
        "    bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "    blob_raw = bucket.blob(f\"raw_data/{datetime.now().strftime('%Y%m%d%H%M%S')}_customer_data_raw.csv\")\n",
        "    blob_raw.upload_from_filename(raw_data_path)\n",
        "    logging.info(f\"Raw data uploaded to GCS: gs://{GCS_BUCKET_NAME}/{blob_raw.name}\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Failed to upload raw data to GCS: {e}\")\n",
        "\n",
        "# --- Uploading to GCS (for processed data) ---\n",
        "try:\n",
        "    blob_processed = bucket.blob(f\"processed_data/{datetime.now().strftime('%Y%m%d%H%M%S')}_customer_data_processed.csv\")\n",
        "    blob_processed.upload_from_filename(processed_data_path)\n",
        "    logging.info(f\"Processed data uploaded to GCS: gs://{GCS_BUCKET_NAME}/{blob_processed.name}\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Failed to upload processed data to GCS: {e}\")\n",
        "\n",
        "\n",
        "# --- Loading to BigQuery (for raw data - example) ---\n",
        "# Note: For production, consider using BigQuery's data loading jobs,\n",
        "# and defining proper table schemas with data quality validation.\n",
        "try:\n",
        "    # Ensure dataset exists\n",
        "    dataset_ref = bigquery_client.dataset(BIGQUERY_DATASET)\n",
        "    try:\n",
        "        bigquery_client.get_dataset(dataset_ref)\n",
        "        logging.info(f\"BigQuery dataset '{BIGQUERY_DATASET}' already exists.\")\n",
        "    except Exception:\n",
        "        bigquery_client.create_dataset(dataset_ref)\n",
        "        logging.info(f\"BigQuery dataset '{BIGQUERY_DATASET}' created.\")\n",
        "\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        source_format=bigquery.SourceFormat.CSV,\n",
        "        skip_leading_rows=1,\n",
        "        autodetect=True, # For simplicity, auto-detect schema. Define explicitly in production!\n",
        "        write_disposition=bigquery.WriteDisposition.WRITE_APPEND # Append to existing table\n",
        "    )\n",
        "\n",
        "    # Load from GCS\n",
        "    #uri = f\"gs://{GCS_BUCKET_NAME}/{blob_raw.name}\"\n",
        "    #load_job = bigquery_client.load_table_from_uri(\n",
        "    #    uri, f\"{BIGQUERY_DATASET}.{BIGQUERY_TABLE}\", job_config=job_config\n",
        "    #)\n",
        "    # Load from local file\n",
        "    with open(raw_data_path, \"rb\") as source_file:\n",
        "        load_job = bigquery_client.load_table_from_file(\n",
        "            source_file, f\"{BIGQUERY_DATASET}.{BIGQUERY_TABLE}\", job_config=job_config\n",
        "        )\n",
        "\n",
        "    load_job.result() # Waits for the job to complete\n",
        "    logging.info(f\"Loaded {load_job.output_rows} rows into BigQuery table {BIGQUERY_DATASET}.{BIGQUERY_TABLE}.\")\n",
        "\n",
        "except Exception as e:\n",
        "    logging.error(f\"Failed to load data to BigQuery: {e}\")\n",
        "\n",
        "print(\"\\n--- Data Stewardship Example Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explanation and How to Use in Jupyter:\n",
        "\n",
        "- **Dependencies:** Ensure you have pandas, google-cloud-storage, and google-cloud-bigquery installed (!pip install ...). If you want more advanced data quality, consider great_expectations.\n",
        "- **GCP Authentication:** If running outside of Colab, make sure your Jupyter environment is authenticated to GCP (e.g., gcloud auth application-default login or by setting the GOOGLE_APPLICATION_CREDENTIALS environment variable).\n",
        "- **Configuration:** Crucially, replace the placeholder values for GCP_PROJECT_ID, GCS_BUCKET_NAME, BIGQUERY_DATASET, and BIGQUERY_TABLE with your actual GCP resource names.\n",
        "- **df_raw (Simulated Raw Data):** This part creates a sample CSV file and loads it into a Pandas DataFrame. It also intentionally introduces some data quality issues (missing values, duplicates, invalid age) to demonstrate the checks.\n",
        "  \n",
        "   - run_data_quality_checks Function:\n",
        "       * This is a simple function to check for common data quality issues: missing values, duplicates, and range violations.\n",
        "       * It prints warnings and collects issues into a quality_report dictionary.\n",
        "       * In a real-world scenario, you'd use more sophisticated libraries like Great Expectations or Pandas Profiling for comprehensive data quality.\n",
        "   - Data Transformation (df_processed): This section simulates common data preprocessing steps like handling missing values and removing duplicates. These are the \"transformations\" that form part of your data lineage.\n",
        "    log_data_artifact_metadata Function:\n",
        "       * This function serves as a basic \"metadata logger.\"\n",
        "       * It captures key details about a data artifact (like its path, hash, row count, and the quality report).\n",
        "        Crucially, it includes upstream_dependencies to manually track lineage. In a real MLOps platform (like Vertex AI Metadata or a dedicated data catalog), this lineage would be automatically captured or easier to integrate.\n",
        "       * It saves this metadata to a JSON file locally.\n",
        "    - GCP Integration (Conceptual): The last part shows where you would typically interact with GCP services:\n",
        "       * **Google Cloud Storage (GCS):** For storing raw and processed datasets. Versioning GCS buckets can also contribute to data versioning.\n",
        "       * **BigQuery:** For analytical datasets. BigQuery itself offers rich metadata and query history for lineage.\n",
        "\n",
        "### What this example demonstrates for Data Stewardship & Governance:\n",
        "\n",
        "- **Data Quality:** Explicitly running checks and generating reports.\n",
        "- **Data Lineage (Manual):** The upstream_dependencies in log_data_artifact_metadata is a manual way to establish parent-child relationships between datasets.\n",
        "- **Metadata Management (Basic):** Storing structured information (metadata) about each data artifact in JSON files.\n",
        "- **Reproducibility (Basic):** The file_hash in the metadata helps ensure you can verify if a data file has changed.\n",
        "\n",
        "This example is a starting point. For a robust MLOps setup, you'd integrate with more mature tools provided by GCP (Vertex AI Metadata, Data Catalog, BigQuery lineage tools) or open-source solutions to automate and scale these governance practices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Concept Drift and Model Monitoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Concept drift and model monitoring are paramount for ensuring your ML models remain effective in production, especially when dealing with real-world, dynamic data. If you're using services like Vertex AI, Vision AI, and Gemini, which often deal with rapidly changing data landscapes (user behavior, world events, new categories, language evolution), actively monitoring for drift is non-negotiable.\n",
        "\n",
        "### What is Concept Drift and Model Monitoring?\n",
        "\n",
        "#### Concept Drift:\n",
        "At its core, concept drift refers to a change in the relationship between the model's inputs (features) and its target variable (what it's trying to predict) over time. This means the underlying \"concept\" or pattern that the model learned during training is no longer valid in the production environment.\n",
        "\n",
        "#### Imagine a model predicting house prices:\n",
        "\n",
        "- Data Drift (Covariate Shift): The average size of houses being sold changes (input features change).\n",
        "- Concept Drift: The market values houses differently, perhaps due to new zoning laws or a sudden shift in buyer preferences (the relationship between house size and price changes).\n",
        "\n",
        "#### Common causes of concept drift include:\n",
        "\n",
        "- Changes in user behavior: New trends, seasonality.\n",
        "- Changes in the real-world environment: Economic shifts, new regulations, pandemics.\n",
        "- Data pipeline issues: Upstream changes that subtly alter feature definitions.\n",
        "- Feedback loops: The model's own predictions influencing user behavior.\n",
        "\n",
        "#### Model Monitoring:\n",
        "Model monitoring is the continuous process of observing and evaluating the performance of deployed machine learning models in real-time. It's about ensuring your models are performing as expected and identifying when they start to degrade, often due to concept drift, data quality issues, or other operational problems.\n",
        "\n",
        "Key aspects of model monitoring include:\n",
        "\n",
        "* **Performance Monitoring:** Tracking actual prediction accuracy, precision, recall, F1-score, AUC, or other relevant metrics (requires ground truth labels, which can be delayed or hard to obtain).\n",
        "* **Data Drift Monitoring:** Detecting changes in the distribution of input features between training data and production data.\n",
        "* **Prediction Drift Monitoring:** Detecting changes in the distribution of model predictions.\n",
        "* **Data Quality Monitoring:** Ensuring the input data remains clean and valid.\n",
        "* **Resource Monitoring:** Tracking latency, throughput, CPU/GPU usage, memory, etc.\n",
        "\n",
        "### Why is it challenging in MLOps (especially with GCP AI)?\n",
        "\n",
        "* **Obtaining Ground Truth:** For many real-world applications (e.g., fraud detection, personalized recommendations), the actual outcome (ground truth) may only be available much later, or not at all. This makes direct performance monitoring difficult.\n",
        "* **High-Dimensional Data:** Detecting drift in text embeddings (from Gemini), image features (from Vision AI), or high-dimensional numerical data is much harder than in simple tabular data.\n",
        "* **Interpretability:** Understanding why a complex model (like a large language model or vision model) is drifting or performing poorly can be incredibly challenging.\n",
        "* **Dynamic Environments:** Real-world data streams are rarely static. Patterns shift, new terms emerge, and user behavior evolves constantly.\n",
        "* **Cost of Retraining:** Retraining large models (especially LLMs or complex Vision models) can be computationally expensive and time-consuming. Automating this process effectively is critical.\n",
        "* **Alert Fatigue:** Setting appropriate thresholds for alerts can be tricky. Too sensitive, and you get flooded with false positives; too lenient, and you miss critical degradation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simple Code Example and Template Snippet (Jupyter Notebook)\n",
        "\n",
        "This example will demonstrate a basic way to:\n",
        "\n",
        "- Simulate data drift in a dataset.\n",
        "- Perform simple statistical tests to detect data drift (a proxy for potential concept drift).\n",
        "- Simulate model predictions and show how you'd track their distribution.\n",
        "- Illustrate where ground truth tracking fits in for performance monitoring.\n",
        "\n",
        "For a production MLOps pipeline, you would use Vertex AI Model Monitoring, which automates much of this, or integrate with other robust MLOps platforms.\n",
        "\n",
        "**Scenario:** You have a model that predicts whether a customer will click on an ad (click_prob). You want to monitor the distribution of a key feature (ad_impressions) and the click_prob itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ks_2samp # Kolmogorov-Smirnov test for distribution comparison\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import logging\n",
        "import json\n",
        "\n",
        "# Set up basic logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "print(\"--- Starting Concept Drift and Model Monitoring Example ---\")\n",
        "\n",
        "# --- Step 1: Simulate Training Data ---\n",
        "np.random.seed(42)\n",
        "num_train_samples = 1000\n",
        "\n",
        "train_data = {\n",
        "    'ad_impressions': np.random.normal(loc=10, scale=3, size=num_train_samples),\n",
        "    'time_on_page': np.random.normal(loc=60, scale=15, size=num_train_samples),\n",
        "    'user_segment': np.random.choice(['A', 'B', 'C'], size=num_train_samples, p=[0.5, 0.3, 0.2]),\n",
        "    'actual_click': np.random.randint(0, 2, size=num_train_samples) # This would be 0 or 1\n",
        "}\n",
        "df_train = pd.DataFrame(train_data)\n",
        "logging.info(f\"Training data simulated. Shape: {df_train.shape}\")\n",
        "\n",
        "# Simulate a very simple model that generates prediction probabilities\n",
        "# In reality, this would come from your actual deployed model\n",
        "def simulate_model_prediction(impressions, time_on_page):\n",
        "    \"\"\"Simple linear-like model for click probability\"\"\"\n",
        "    return 1 / (1 + np.exp(-(0.1 * impressions + 0.05 * time_on_page - 5))) # Sigmoid function\n",
        "\n",
        "df_train['predicted_click_prob'] = simulate_model_prediction(df_train['ad_impressions'], df_train['time_on_page'])\n",
        "logging.info(\"Simulated initial model predictions on training data.\")\n",
        "\n",
        "\n",
        "# --- Step 2: Simulate Production Data Over Time with Drift ---\n",
        "num_production_days = 7\n",
        "production_data_streams = []\n",
        "\n",
        "for day in range(num_production_days):\n",
        "    current_date = datetime.now() - timedelta(days=num_production_days - 1 - day)\n",
        "    num_samples_day = 200 # Daily volume\n",
        "\n",
        "    # Simulate base production data\n",
        "    daily_data = {\n",
        "        'ad_impressions': np.random.normal(loc=10, scale=3, size=num_samples_day),\n",
        "        'time_on_page': np.random.normal(loc=60, scale=15, size=num_samples_day),\n",
        "        'user_segment': np.random.choice(['A', 'B', 'C'], size=num_samples_day, p=[0.5, 0.3, 0.2]),\n",
        "        'prediction_timestamp': [current_date] * num_samples_day\n",
        "    }\n",
        "    df_day = pd.DataFrame(daily_data)\n",
        "\n",
        "    # Introduce DATA DRIFT after a few days (e.g., from day 4 onwards, impressions increase)\n",
        "    if day >= 3:\n",
        "        drift_factor = 2 # Increase mean impressions\n",
        "        df_day['ad_impressions'] = np.random.normal(loc=10 + drift_factor, scale=3, size=num_samples_day)\n",
        "        logging.info(f\"Day {day+1}: Introducing data drift in 'ad_impressions'.\")\n",
        "\n",
        "    # Introduce CONCEPT DRIFT (e.g., from day 5, the relationship between impressions and click changes)\n",
        "    # This is harder to simulate directly without a true model, but we'll show its effect\n",
        "    if day >= 4:\n",
        "        # Simulate a scenario where higher impressions now lead to slightly lower click probabilities\n",
        "        # due to user fatigue, even if the model doesn't know it.\n",
        "        df_day['predicted_click_prob'] = simulate_model_prediction(\n",
        "            df_day['ad_impressions'], df_day['time_on_page']\n",
        "        ) - (df_day['ad_impressions'] * 0.01) # Small negative impact due to drift\n",
        "        logging.info(f\"Day {day+1}: Simulating effect of concept drift on 'predicted_click_prob'.\")\n",
        "    else:\n",
        "        df_day['predicted_click_prob'] = simulate_model_prediction(df_day['ad_impressions'], df_day['time_on_page'])\n",
        "\n",
        "\n",
        "    # Simulate ground truth (e.g., actual clicks available the next day)\n",
        "    # For simplicity, we'll assign it here. In reality, this is delayed.\n",
        "    df_day['actual_click'] = (df_day['predicted_click_prob'] + np.random.normal(0, 0.1, num_samples_day) > 0.5).astype(int)\n",
        "    # Simulate a delay in ground truth for monitoring\n",
        "    df_day['ground_truth_available_date'] = current_date + timedelta(days=1)\n",
        "\n",
        "    production_data_streams.append(df_day)\n",
        "\n",
        "df_production = pd.concat(production_data_streams).reset_index(drop=True)\n",
        "logging.info(f\"Production data simulated over {num_production_days} days. Total shape: {df_production.shape}\")\n",
        "\n",
        "\n",
        "# --- Step 3: Model Monitoring - Data Drift Detection ---\n",
        "\n",
        "def detect_data_drift(\n",
        "    train_feature_data,\n",
        "    prod_feature_data,\n",
        "    feature_name,\n",
        "    p_value_threshold=0.05,\n",
        "    visualize=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Compares the distribution of a feature between training and production data\n",
        "    using the Kolmogorov-Smirnov (KS) test.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Checking data drift for feature: '{feature_name}'...\")\n",
        "\n",
        "    # Filter out NaNs for KS test\n",
        "    train_clean = train_feature_data.dropna()\n",
        "    prod_clean = prod_feature_data.dropna()\n",
        "\n",
        "    if train_clean.empty or prod_clean.empty:\n",
        "        logging.warning(f\"Skipping drift detection for '{feature_name}' due to empty data after NaN removal.\")\n",
        "        return {'feature': feature_name, 'drift_detected': False, 'p_value': None, 'message': 'Insufficient data'}\n",
        "\n",
        "    statistic, p_value = ks_2samp(train_clean, prod_clean)\n",
        "\n",
        "    drift_detected = p_value < p_value_threshold\n",
        "    message = f\"KS-test p-value: {p_value:.4f}. {'DRIFT DETECTED!' if drift_detected else 'No significant drift.'}\"\n",
        "    logging.info(f\"  -> {message}\")\n",
        "\n",
        "    if visualize:\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        sns.histplot(train_clean, color='blue', label='Training Data', kde=True, stat='density', alpha=0.5)\n",
        "        sns.histplot(prod_clean, color='red', label='Production Data', kde=True, stat='density', alpha=0.5)\n",
        "        plt.title(f'Distribution Comparison for {feature_name}\\n(Drift Detected: {drift_detected})')\n",
        "        plt.xlabel(feature_name)\n",
        "        plt.ylabel('Density')\n",
        "        plt.legend()\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        plt.show()\n",
        "\n",
        "    return {\n",
        "        'feature': feature_name,\n",
        "        'drift_detected': drift_detected,\n",
        "        'p_value': p_value,\n",
        "        'message': message\n",
        "    }\n",
        "\n",
        "# Monitor 'ad_impressions' for data drift\n",
        "drift_report_impressions = detect_data_drift(\n",
        "    df_train['ad_impressions'],\n",
        "    df_production['ad_impressions'],\n",
        "    'ad_impressions',\n",
        "    visualize=True # Set to False if you don't want plots\n",
        ")\n",
        "\n",
        "# Monitor 'time_on_page' (should show no drift)\n",
        "drift_report_time_on_page = detect_data_drift(\n",
        "    df_train['time_on_page'],\n",
        "    df_production['time_on_page'],\n",
        "    'time_on_page',\n",
        "    visualize=True\n",
        ")\n",
        "\n",
        "print(\"\\n--- Data Drift Reports ---\")\n",
        "print(json.dumps(drift_report_impressions, indent=2))\n",
        "print(json.dumps(drift_report_time_on_page, indent=2))\n",
        "\n",
        "# --- Step 4: Model Monitoring - Prediction Drift and Performance Monitoring ---\n",
        "\n",
        "def monitor_predictions_and_performance(\n",
        "    production_df,\n",
        "    prediction_col,\n",
        "    ground_truth_col,\n",
        "    time_col='prediction_timestamp',\n",
        "    ground_truth_time_col='ground_truth_available_date',\n",
        "    window_size_days=1, # Analyze daily batches\n",
        "    performance_metric=None # e.g., 'accuracy' if binary classification\n",
        "):\n",
        "    \"\"\"\n",
        "    Monitors prediction distribution and (if ground truth available) model performance over time.\n",
        "    \"\"\"\n",
        "    monitoring_reports = []\n",
        "    daily_data = production_df.groupby(pd.Grouper(key=time_col, freq=f'{window_size_days}D'))\n",
        "\n",
        "    for day, df_batch in daily_data:\n",
        "        if df_batch.empty:\n",
        "            continue\n",
        "\n",
        "        report = {\n",
        "            'date': day.strftime('%Y-%m-%d'),\n",
        "            'num_predictions': len(df_batch),\n",
        "            'prediction_stats': {\n",
        "                'mean': df_batch[prediction_col].mean(),\n",
        "                'std': df_batch[prediction_col].std(),\n",
        "                'min': df_batch[prediction_col].min(),\n",
        "                'max': df_batch[prediction_col].max(),\n",
        "                'median': df_batch[prediction_col].median()\n",
        "            },\n",
        "            'performance': {\n",
        "                'metric_name': performance_metric,\n",
        "                'value': None,\n",
        "                'available_ground_truth_count': 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Check for ground truth availability for this batch\n",
        "        # Filter for ground truth that is available by the current 'day'\n",
        "        available_ground_truth_df = df_batch[df_batch[ground_truth_time_col] <= day]\n",
        "\n",
        "        if not available_ground_truth_df.empty and performance_metric:\n",
        "            true_labels = available_ground_truth_df[ground_truth_col]\n",
        "            predictions = (available_ground_truth_df[prediction_col] > 0.5).astype(int) # Binary prediction from probability\n",
        "\n",
        "            if performance_metric == 'accuracy':\n",
        "                from sklearn.metrics import accuracy_score\n",
        "                score = accuracy_score(true_labels, predictions)\n",
        "                report['performance']['value'] = score\n",
        "                report['performance']['available_ground_truth_count'] = len(available_ground_truth_df)\n",
        "                logging.info(f\"Day {day.strftime('%Y-%m-%d')}: Performance - Accuracy = {score:.4f} ({len(available_ground_truth_df)} ground truths).\")\n",
        "\n",
        "        monitoring_reports.append(report)\n",
        "\n",
        "    # Visualize Prediction Distribution over time\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    dates = [pd.to_datetime(r['date']) for r in monitoring_reports]\n",
        "    means = [r['prediction_stats']['mean'] for r in monitoring_reports]\n",
        "    stds = [r['prediction_stats']['std'] for r in monitoring_reports]\n",
        "\n",
        "    plt.plot(dates, means, label=f'Mean {prediction_col}', marker='o')\n",
        "    plt.fill_between(dates, np.array(means) - np.array(stds), np.array(means) + np.array(stds), color='blue', alpha=0.1, label='Std Dev Range')\n",
        "    plt.title(f'Mean {prediction_col} Over Time')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel(f'Mean {prediction_col}')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Visualize Performance Metric over time (if available)\n",
        "    if performance_metric:\n",
        "        perf_values = [r['performance']['value'] for r in monitoring_reports if r['performance']['value'] is not None]\n",
        "        perf_dates = [pd.to_datetime(r['date']) for r in monitoring_reports if r['performance']['value'] is not None]\n",
        "        if perf_values:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(perf_dates, perf_values, label=f'{performance_metric.capitalize()} Over Time', marker='o', color='green')\n",
        "            plt.title(f'Model {performance_metric.capitalize()} Over Time')\n",
        "            plt.xlabel('Date')\n",
        "            plt.ylabel(performance_metric.capitalize())\n",
        "            plt.grid(True)\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "    return monitoring_reports\n",
        "\n",
        "monitoring_summary = monitor_predictions_and_performance(\n",
        "    df_production,\n",
        "    prediction_col='predicted_click_prob',\n",
        "    ground_truth_col='actual_click',\n",
        "    performance_metric='accuracy'\n",
        ")\n",
        "\n",
        "print(\"\\n--- Daily Prediction & Performance Monitoring Summary ---\")\n",
        "for report in monitoring_summary:\n",
        "    print(json.dumps(report, indent=2))\n",
        "\n",
        "print(\"\\n--- Concept Drift and Model Monitoring Example Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explanation and How to Use in Jupyter:\n",
        "\n",
        "- **Dependencies:** Ensure you have pandas, numpy, scipy, matplotlib, and seaborn installed (!pip install ...). For the accuracy_score metric, you'll also need scikit-learn (!pip install scikit-learn).\n",
        "\n",
        "- **Simulate Training Data:** We create a df_train DataFrame representing the data your model was initially trained on. A simple simulate_model_prediction function is included to generate predicted_click_prob.\n",
        "\n",
        "- Simulate Production Data with Drift:\n",
        "   - This loop generates daily batches of \"production\" data.\n",
        "   - **Data Drift:** From day >= 3, we subtly shift the mean of ad_impressions to simulate real-world changes. You'll see this in the first histogram.\n",
        "   - **Concept Drift:** From day >= 4, we alter how predicted_click_prob is generated. Even if ad_impressions changes, the relationship between impressions and click_prob is now different. This is the hardest to detect without ground truth, but it will show up in the actual performance degradation later.\n",
        "   - **Simulated Ground Truth Delay:** Notice ground_truth_available_date. This simulates the common scenario where actual outcomes are only known a day or more after the prediction.\n",
        "\n",
        "- detect_data_drift Function:\n",
        "    - This function compares the distribution of a specified feature between your training dataset and a production dataset.\n",
        "    - It uses the Kolmogorov-Smirnov (KS) test (scipy.stats.ks_2samp). The KS test checks if two samples are drawn from the same continuous distribution. A low p-value (e.g., < 0.05) suggests they are likely from different distributions, indicating drift.\n",
        "    - It also generates histograms to visually compare the distributions, which is very helpful for understanding the drift.\n",
        "    - **Limitations:** KS test is sensitive to sample size and works best for continuous features. For categorical features, you'd use a chi-squared test. For high-dimensional data, you might need more advanced techniques like adversarial autoencoders or deep divergence metrics.\n",
        "\n",
        "- monitor_predictions_and_performance Function:\n",
        "    - This function groups production data by time (daily in this case).\n",
        "    - **Prediction Drift:** It calculates descriptive statistics (mean, std, min, max, median) of the predicted_click_prob for each day. Changes in these stats can indicate prediction drift.\n",
        "    - **Performance Monitoring:** If ground truth (actual_click) is available for a given day (based on ground_truth_time_col), it calculates a specified performance metric (e.g., accuracy_score).\n",
        "    - **Visualizations:** It plots the mean prediction probability over time and the model's accuracy over time (if ground truth is available). These plots are crucial for spotting trends and sudden drops.\n",
        "\n",
        "- **Running the Monitoring**: The last section calls these functions and prints their reports.\n",
        "\n",
        "### What this example demonstrates for Concept Drift & Model Monitoring:\n",
        "\n",
        "- **Data Drift Detection:** How to use a statistical test (KS test) and visualizations to identify changes in feature distributions.\n",
        "- **Prediction Drift Tracking:** How to monitor the statistical properties of your model's outputs over time.\n",
        "- **Performance Monitoring with Delayed Ground Truth:** How to calculate actual model performance as ground truth becomes available.\n",
        "- **The Link between Drift and Performance:** In the simulated example, the data drift in ad_impressions and the subtle concept drift will eventually lead to a noticeable drop in the accuracy metric, showing how these issues manifest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Next Steps for a Real-World Scenario (especially with GCP Vertex AI):\n",
        "\n",
        "- **Vertex AI Model Monitoring:** For production, you would leverage Vertex AI Model Monitoring. It automates drift detection (for features and predictions) and performance monitoring. You define monitoring jobs, specify target metrics, and integrate with Cloud Logging and Cloud Monitoring for alerts. It uses techniques beyond simple KS tests, like L1 distance, Jensen-Shannon divergence, and automatically sets baselines.\n",
        "- **Feature Store Integration:** For more robust monitoring, integrate with Vertex AI Feature Store. This ensures consistent features for both training and serving, simplifying drift detection.\n",
        "- **Automated Retraining:** Once drift is detected and performance degrades, you'd trigger a Vertex AI Pipeline to automatically retrain the model with fresh data and redeploy it, closing the MLOps loop.\n",
        "- **Custom Metrics and Explainability:** For complex models like Gemini or Vision AI, you'd need to define custom metrics for monitoring (e.g., perplexity for LLMs, specific error types for Vision) and potentially integrate with explainability tools (like Vertex Explainable AI) to understand why a model is misbehaving.\n",
        "- **Thresholds and Alerting:** Carefully define alert thresholds based on your business tolerance for degradation and integrate with Cloud Monitoring Alerts, Slack, PagerDuty, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Debugging Complex ML Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's absolutely dive into Debugging Complex ML Systems! This is often the most frustrating and time-consuming part of the MLOps lifecycle, and it gets exponentially harder with advanced models and distributed platforms like GCP's Vertex AI, Vision AI, and Gemini.\n",
        "\n",
        "You've likely experienced the pain: your model performs great in development, but then in production, it throws unexpected errors, generates nonsensical outputs, or silently degrades. Pinpointing the root cause in an interconnected ML system can feel like finding a needle in a haystack.\n",
        "\n",
        "### What Makes Debugging Complex ML Systems So Hard?\n",
        "\n",
        "Traditional software debugging involves stepping through code, inspecting variables, and analyzing stack traces. While those are still relevant in ML, there are several added layers of complexity:\n",
        "\n",
        "- Non-Determinism:\n",
        "    - **Randomness:** Many ML algorithms (e.g., neural network weight initialization, dropout, shuffling) involve randomness. This means running the same code with the same data can sometimes produce slightly different results, making it hard to reproduce a specific bug.\n",
        "    - **Distributed Training:** In large-scale distributed training (common for Gemini-sized models), the order of operations or data synchronization can introduce subtle non-determinism.\n",
        "\n",
        "Data-Dependent Bugs:\n",
        "- **Data Quality:** As we discussed, a small issue in your raw data, a subtle error in a preprocessing step, or a data skew in production can lead to unexpected model behavior. These aren't \"code bugs\" in the traditional sense.\n",
        "- **Edge Cases:** Models might perform well on average but fail catastrophically on rare, yet important, edge cases in the data that weren't adequately represented in training.\n",
        "- **Data Labeling Errors:** Mistakes in your ground truth labels can lead the model to learn incorrect patterns, resulting in poor performance that's hard to trace back.\n",
        "\n",
        "Black-Box Models:\n",
        "- **Deep Learning Opacity:** Modern deep learning models (like those powering Vision AI and Gemini) are highly complex, with millions or billions of parameters. It's incredibly difficult to interpret why a specific prediction was made or why a particular error occurred.\n",
        "- **Foundation Model Nuances:** With Gemini, for example, the model's behavior is influenced by its vast pre-training data, fine-tuning, and prompt engineering. A \"bug\" might not be in your code but in how you're prompting the model or in its inherent biases.\n",
        "\n",
        "Distributed Systems and Pipelines:\n",
        "- **Orchestration Complexity:** MLOps pipelines often span multiple services (data ingestion, feature store, training, serving, monitoring) orchestrated by tools like Vertex AI Pipelines. A failure can occur at any stage, and tracing it across services and logs can be daunting.\n",
        "\n",
        "- **Inter-Service Communication:** Issues with APIs, network latency, or data serialization between different components (e.g., Feature Store to Training Job, Model Endpoint to Client Application) can cause hard-to-diagnose bugs.\n",
        "\n",
        "- **Lack of Real-Time Ground Truth:**\n",
        "    Debugging performance issues is much harder when you don't immediately know if the model's predictions are correct. You might only get ground truth weeks or months later, making root cause analysis a retrospective challenge.\n",
        "\n",
        " - Resource Management Issues:\n",
        "    - **GPU/TPU Utilization:** Poor utilization, memory leaks, or incorrect batch sizing on accelerators can lead to slow training, out-of-memory errors, or outright crashes, which are often difficult to diagnose without specialized profiling tools."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategies and Tools for Debugging Complex ML Systems on GCP:\n",
        "\n",
        "- **Reproducibility:** This is your North Star.\n",
        "   - **Version Control Everything:** Code, data, environments (Docker images, dependency files), model checkpoints.\n",
        "   - **Seed Randomness:** Use np.random.seed(), tf.random.set_seed(), etc., to make training runs more deterministic.\n",
        "   - **Containerization (Docker/Vertex AI Custom Containers):** Package your code and dependencies consistently.\n",
        "\n",
        "- **Observability:** Knowing what's happening at every stage.\n",
        "- **Comprehensive Logging:** Log granular information (input shapes, intermediate values, hyperparameters, version info) at critical points in your data pipelines, training jobs, and serving endpoints. Use Cloud Logging for centralized collection.\n",
        "- **Distributed Tracing:** Tools like Cloud Trace can help visualize the flow of requests through different microservices in your serving architecture.\n",
        "- **Monitoring and Alerting:** As discussed, monitor key metrics (data drift, prediction drift, resource utilization, latency, error rates) and set up alerts in Cloud Monitoring.\n",
        "\n",
        "Data Validation and Profiling:\n",
        "- **Pre-Training Validation:** Use tools like Great Expectations or TFX Data Validation to validate data schemas, ranges, and distributions before training.\n",
        "- **Post-Inference Validation:** Continuously validate the schema and quality of data flowing into your production models.\n",
        "- **Data Profiling:** Understand the statistical properties of your data at various stages (raw, processed, features).\n",
        "\n",
        "Model-Specific Debugging:\n",
        "- **Explainable AI (XAI) (Vertex Explainable AI):** For tabular and image data, XAI can provide insights into why a model made a specific prediction (e.g., feature attributions, saliency maps). This helps diagnose concept drift or data-dependent bugs.\n",
        "- **Error Analysis:** Don't just look at overall accuracy. Analyze specific types of errors your model makes. What characteristics do the misclassified samples share?\n",
        "- **Prompt Engineering Best Practices (for Gemini):** Debugging Gemini often involves refining prompts, understanding its temperature/top-k/top-p settings, and being aware of its safety filters.\n",
        "\n",
        "GCP-Specific Tools:\n",
        "- **Vertex AI Metadata:** Crucial for tracking lineage of artifacts (datasets, models, pipelines). If a model is buggy, you can trace back to the exact data and code version used.\n",
        "- **Vertex AI Experiment Tracking:** Log hyperparameters, metrics, and model artifacts for each experiment run. This helps compare runs and identify when performance started to degrade.\n",
        "- **Vertex AI Model Monitoring:** Automates the detection of drift and performance degradation.\n",
        "- **Cloud Logging & Cloud Monitoring:** Centralized logs and metrics for all GCP services. Essential for distributed debugging.\n",
        "- **Cloud Build (for CI/CD):** Ensure consistent build environments.\n",
        "- **TensorBoard (with Vertex AI Training):** Visualize training metrics, loss curves, and model graphs, which can reveal training instabilities or issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simple Code Example and Template Snippet (Jupyter Notebook)\n",
        "\n",
        "This example focuses on reproducibility (seeding randomness, logging environment details) and data-dependent debugging (basic data validation/profiling for identifying issues before they hit the model). It's a template for what you might add to your feature engineering or training notebooks.\n",
        "\n",
        "**Scenario:** You're training a simple classification model. You want to ensure reproducibility and catch potential data issues early."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "from datetime import datetime\n",
        "import hashlib # For data integrity/versioning\n",
        "import sys # To capture Python version\n",
        "\n",
        "# --- Debugging Configuration ---\n",
        "RANDOM_SEED = 42 # Master seed for reproducibility\n",
        "LOG_LEVEL = logging.INFO # Set to logging.DEBUG for more verbose output\n",
        "\n",
        "# Set up basic logging\n",
        "logging.basicConfig(level=LOG_LEVEL, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "print(f\"--- Starting ML System Debugging Example ---\")\n",
        "logging.info(f\"Using RANDOM_SEED: {RANDOM_SEED}\")\n",
        "\n",
        "# --- Step 1: Ensure Reproducibility (Seeding Randomness & Environment Logging) ---\n",
        "# Set seeds for various libraries\n",
        "np.random.seed(RANDOM_SEED)\n",
        "# For TensorFlow/Keras: tf.random.set_seed(RANDOM_SEED)\n",
        "# For PyTorch: torch.manual_seed(RANDOM_SEED)\n",
        "# For Scikit-learn, many estimators accept a random_state parameter\n",
        "\n",
        "# Log environment details for reproducibility\n",
        "env_details = {\n",
        "    'python_version': sys.version,\n",
        "    'pandas_version': pd.__version__,\n",
        "    'numpy_version': np.__version__,\n",
        "    'sklearn_version': sklearn.__version__, # assuming sklearn is imported\n",
        "    'current_timestamp': datetime.now().isoformat(),\n",
        "    'notebook_name': os.path.basename(os.getcwd()) # This might vary based on your Jupyter setup\n",
        "}\n",
        "logging.info(f\"Environment Details for Reproducibility:\\n{json.dumps(env_details, indent=2)}\")\n",
        "\n",
        "# --- Step 2: Simulate Data with Potential Issues ---\n",
        "num_samples = 1000\n",
        "\n",
        "# Create a clean base data\n",
        "data = {\n",
        "    'feature_1': np.random.rand(num_samples) * 100,\n",
        "    'feature_2': np.random.randint(0, 5, num_samples),\n",
        "    'feature_3': np.random.normal(loc=50, scale=10, size=num_samples),\n",
        "    'target': np.random.randint(0, 2, num_samples) # Binary target\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Introduce a data quality issue: missing values in feature_1\n",
        "missing_idx = np.random.choice(df.index, size=int(0.05 * num_samples), replace=False)\n",
        "df.loc[missing_idx, 'feature_1'] = np.nan\n",
        "logging.info(f\"Introduced 5% missing values in 'feature_1'.\")\n",
        "\n",
        "# Introduce a potential \"outlier\" or invalid range in feature_3\n",
        "df.loc[np.random.choice(df.index, size=5, replace=False), 'feature_3'] = -999 # Clearly invalid value\n",
        "logging.info(f\"Introduced 5 invalid values (-999) in 'feature_3'.\")\n",
        "\n",
        "# Simulate a potential data type issue for feature_2 if it came from an external source\n",
        "# df['feature_2'] = df['feature_2'].astype(str) # This would require a type conversion later\n",
        "# logging.info(f\"Simulated feature_2 as string type.\")\n",
        "\n",
        "print(\"\\n--- Raw Data Snippet (with introduced issues) ---\")\n",
        "print(df.head())\n",
        "\n",
        "# --- Step 3: Data Validation and Profiling (Crucial for Data-Dependent Bugs) ---\n",
        "def basic_data_validation(dataframe, stage_name=\"Raw Data\"):\n",
        "    \"\"\"\n",
        "    Performs basic validation checks on a DataFrame.\n",
        "    Returns True if valid, False otherwise.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Running data validation for: {stage_name}\")\n",
        "    is_valid = True\n",
        "    issues = []\n",
        "\n",
        "    # Check for missing values\n",
        "    missing_counts = dataframe.isnull().sum()\n",
        "    if missing_counts.sum() > 0:\n",
        "        for col, count in missing_counts.items():\n",
        "            if count > 0:\n",
        "                issues.append(f\"Column '{col}' has {count} missing values.\")\n",
        "                logging.warning(f\"Validation Warning: {col} has {count} missing values.\")\n",
        "        is_valid = False\n",
        "\n",
        "    # Check for invalid ranges/outliers (example for 'feature_3')\n",
        "    if 'feature_3' in dataframe.columns and (dataframe['feature_3'] < 0).any():\n",
        "        issues.append(f\"Column 'feature_3' contains negative values (e.g., -999) which might be invalid.\")\n",
        "        logging.warning(f\"Validation Warning: 'feature_3' contains unexpected negative values.\")\n",
        "        is_valid = False\n",
        "\n",
        "    # Check for expected data types (example for 'feature_2' expecting integer)\n",
        "    if 'feature_2' in dataframe.columns and not pd.api.types.is_numeric_dtype(dataframe['feature_2']):\n",
        "        issues.append(f\"Column 'feature_2' is not numeric (found {dataframe['feature_2'].dtype}). Expected numeric.\")\n",
        "        logging.warning(f\"Validation Warning: 'feature_2' is not numeric.\")\n",
        "        is_valid = False\n",
        "\n",
        "    if not is_valid:\n",
        "        logging.error(f\"Data validation FAILED for {stage_name}. Issues: {issues}\")\n",
        "    else:\n",
        "        logging.info(f\"Data validation PASSED for {stage_name}.\")\n",
        "    return is_valid, issues\n",
        "\n",
        "is_raw_data_valid, raw_issues = basic_data_validation(df, stage_name=\"Raw Data Before Preprocessing\")\n",
        "\n",
        "# --- Step 4: Data Preprocessing (Addressing identified issues) ---\n",
        "logging.info(\"Starting data preprocessing...\")\n",
        "\n",
        "# Handle missing values (e.g., median imputation)\n",
        "df['feature_1'].fillna(df['feature_1'].median(), inplace=True)\n",
        "logging.info(\"Missing values in 'feature_1' imputed with median.\")\n",
        "\n",
        "# Handle invalid ranges/outliers (e.g., cap or replace with NaN then impute)\n",
        "# For -999, let's treat it as a sentinel value that needs imputation\n",
        "df.loc[df['feature_3'] < 0, 'feature_3'] = np.nan\n",
        "df['feature_3'].fillna(df['feature_3'].median(), inplace=True) # Impute after setting to NaN\n",
        "logging.info(\"Invalid values (-999) in 'feature_3' handled by imputation.\")\n",
        "\n",
        "# Ensure correct data types (if needed, e.g., if feature_2 was str)\n",
        "# df['feature_2'] = pd.to_numeric(df['feature_2'], errors='coerce')\n",
        "# df['feature_2'].fillna(df['feature_2'].median(), inplace=True) # Handle conversion errors\n",
        "\n",
        "logging.info(\"Data preprocessing complete.\")\n",
        "\n",
        "# Re-validate after preprocessing\n",
        "is_processed_data_valid, processed_issues = basic_data_validation(df, stage_name=\"Processed Data Before Training\")\n",
        "\n",
        "# Fail fast if data is not valid for training\n",
        "if not is_processed_data_valid:\n",
        "    logging.critical(\"Processed data is NOT valid for training. Aborting training process.\")\n",
        "    # In a real pipeline, you'd raise an exception or trigger an alert\n",
        "    # raise ValueError(\"Data validation failed after preprocessing.\")\n",
        "\n",
        "\n",
        "# --- Step 5: Model Training (with reproducibility) ---\n",
        "logging.info(\"Splitting data and training model...\")\n",
        "\n",
        "X = df[['feature_1', 'feature_2', 'feature_3']]\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y)\n",
        "logging.info(f\"Data split into train ({X_train.shape}) and test ({X_test.shape}) sets.\")\n",
        "\n",
        "# Model Initialization with random_state for reproducibility\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED, n_jobs=-1)\n",
        "model.fit(X_train, y_train)\n",
        "logging.info(\"Model training complete.\")\n",
        "\n",
        "# --- Step 6: Model Evaluation and Basic Debugging (Error Analysis) ---\n",
        "logging.info(\"Evaluating model performance...\")\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "logging.info(f\"Model Accuracy on test set: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Basic Error Analysis: Look at misclassified samples\n",
        "misclassified_indices = np.where(y_test != y_pred)[0]\n",
        "if len(misclassified_indices) > 0:\n",
        "    logging.warning(f\"Found {len(misclassified_indices)} misclassified samples in the test set.\")\n",
        "    misclassified_samples = X_test.iloc[misclassified_indices]\n",
        "    misclassified_actual = y_test.iloc[misclassified_indices]\n",
        "    misclassified_pred = y_pred[misclassified_indices]\n",
        "\n",
        "    print(\"\\n--- Misclassified Samples (first 5) ---\")\n",
        "    misclassified_df = pd.DataFrame({\n",
        "        'predicted': misclassified_pred,\n",
        "        'actual': misclassified_actual.values,\n",
        "        **misclassified_samples.head().to_dict('list')\n",
        "    })\n",
        "    print(misclassified_df.head())\n",
        "    # You would then analyze these samples: are they true edge cases? Data errors? Model biases?\n",
        "else:\n",
        "    logging.info(\"No misclassified samples found in the test set (or very few).\")\n",
        "\n",
        "# --- Template Snippet for GCP Logging / Vertex AI Tracking ---\n",
        "# This part is conceptual. In a real scenario, these would be API calls.\n",
        "def log_to_cloud_logging(log_name, message, severity='INFO', labels=None):\n",
        "    \"\"\"Simulates sending a log entry to Google Cloud Logging.\"\"\"\n",
        "    log_entry = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'severity': severity,\n",
        "        'message': message,\n",
        "        'labels': labels if labels else {}\n",
        "    }\n",
        "    # In real code: from google.cloud import logging\n",
        "    # client = logging.Client()\n",
        "    # logger = client.logger(log_name)\n",
        "    # logger.log_struct(log_entry, severity=severity)\n",
        "    logging.debug(f\"[Cloud Logging Sim] Logged to '{log_name}': {json.dumps(log_entry)}\")\n",
        "\n",
        "def log_vertex_ai_experiment_metric(metric_name, value, step=0):\n",
        "    \"\"\"Simulates logging a metric to Vertex AI Experiment Tracking.\"\"\"\n",
        "    # In real code: from google.cloud import aiplatform\n",
        "    # aiplatform.init(project=GCP_PROJECT_ID, location=GCP_REGION)\n",
        "    # experiment_run.log_metrics({metric_name: value}, step=step)\n",
        "    logging.debug(f\"[Vertex AI Experiment Sim] Logged metric '{metric_name}': {value} at step {step}\")\n",
        "\n",
        "log_to_cloud_logging(\n",
        "    log_name=\"model_training_pipeline\",\n",
        "    message=\"Starting model training run.\",\n",
        "    labels={\"pipeline_stage\": \"training\", \"model_version\": \"v1.0\"}\n",
        ")\n",
        "\n",
        "log_vertex_ai_experiment_metric(\"test_accuracy\", accuracy)\n",
        "log_vertex_ai_experiment_metric(\"train_samples\", X_train.shape[0])\n",
        "log_vertex_ai_experiment_metric(\"test_samples\", X_test.shape[0])\n",
        "\n",
        "log_to_cloud_logging(\n",
        "    log_name=\"model_training_pipeline\",\n",
        "    message=\"Model training and evaluation complete.\",\n",
        "    severity=\"INFO\",\n",
        "    labels={\"pipeline_stage\": \"evaluation\", \"model_accuracy\": f\"{accuracy:.4f}\"}\n",
        ")\n",
        "\n",
        "print(\"\\n--- ML System Debugging Example Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explanation and How to Use in Jupyter:\n",
        "\n",
        "- **Dependencies:** Ensure you have pandas, numpy, scikit-learn, matplotlib, and seaborn installed.\n",
        "- **RANDOM_SEED:** This is crucial. Setting a master seed for numpy (and tensorflow/pytorch if you use them) helps ensure that if you run the same notebook with the same data, you get identical (or very close) results. This makes bugs reproducible!\n",
        "- **Environment Logging:** Capturing Python and library versions is vital. A bug might only appear with a specific version of a dependency.\n",
        "\n",
        "Simulate Data with Issues: We intentionally create a dataset with:\n",
        "- Missing values (np.nan) in feature_1.\n",
        "- An invalid sentinel value (-999) in feature_3 that might indicate data ingestion errors.\n",
        "- This is a common source of \"data-dependent bugs\" that are hard to spot without explicit validation.\n",
        "\n",
        "basic_data_validation Function:\n",
        "- This is your frontline defense against data-related bugs.\n",
        "- It checks for missing values, out-of-range values, and incorrect data types.\n",
        "- Crucially, it logs warnings/errors and returns a boolean is_valid flag. In a real pipeline, if is_valid is False, you'd typically stop the pipeline, alert the team, and prevent bad data from reaching your model. This is the \"fail-fast\" principle.\n",
        "\n",
        "- **Data Preprocessing:** Shows how you'd typically clean the data to address the issues found during validation.\n",
        "- **Model Training:** A standard RandomForestClassifier is used. Notice random_state=RANDOM_SEED for reproducibility in the train_test_split and RandomForestClassifier.\n",
        "\n",
        "Error Analysis:\n",
        "- Beyond just printing the classification report, this section demonstrates how to find and inspect misclassified samples.\n",
        "- This is key for debugging black-box models: If you can't understand why the model did something, look at what kinds of things it's getting wrong. Are they consistently from a certain class, demographic, or data characteristic? This points to bias, insufficient training data for certain scenarios, or concept drift."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GCP Logging / Vertex AI Tracking (Conceptual):\n",
        "\n",
        "- These helper functions (log_to_cloud_logging, log_vertex_ai_experiment_metric) illustrate where you would integrate with GCP's powerful observability tools.\n",
        "- **Cloud Logging:** For centralized collection of all your print statements, logging messages, and custom structured logs from your training jobs, serving endpoints, and pipelines.\n",
        "- **Vertex AI Experiment Tracking:** To log metrics (accuracy, loss, F1-score), hyperparameters, and artifact versions for each training run. This allows you to compare runs and pinpoint when performance changed.\n",
        "\n",
        "#### Debugging Workflow on GCP:\n",
        "\n",
        "- **Start with Observability:** When a bug occurs, first check your Cloud Logging for errors or warnings in your training job logs, serving logs, or pipeline logs. Look for specific error messages or stack traces.\n",
        "- **Monitor Metrics:** Check Cloud Monitoring and Vertex AI Model Monitoring dashboards for sudden drops in performance, spikes in error rates, or data/prediction drift.\n",
        "- **Trace Lineage:** Use Vertex AI Metadata to trace back from the faulty model to the exact dataset version and code/pipeline run that produced it.\n",
        "\n",
        "   - **Inspect Data:** If drift is detected or performance is dropping, profile the incoming production data using BigQuery, Dataflow, or Dataproc. Compare its distributions with your training data.\n",
        "   - **Re-run Experiment (Reproducibly):** If the bug is reproducible, try to re-run the exact experiment using the logged hyperparameters, data versions, and environment configurations in a controlled environment (e.g., a Vertex AI Workbench notebook or a Vertex AI Custom Training Job).\n",
        "   - **Error Analysis:** Analyze the misclassified samples in your development environment to understand patterns. Use Vertex Explainable AI if applicable to gain insights into model decisions.\n",
        "   - **Isolate Components:** If a bug occurs in a pipeline, try to isolate the problematic step. Run that step independently with controlled inputs to debug it.\n",
        "   - **Iterate and Test:** Implement a fix, and rigorously test it, ideally with automated tests (unit tests for code, integration tests for pipelines, and data validation tests).\n",
        "\n",
        "Debugging complex ML systems is a continuous process of disciplined logging, systematic observation, and hypothesis testing. By integrating these practices into your MLOps workflow, you can significantly reduce the time and effort spent chasing elusive bugs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Skill Gaps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Common Skill Gaps in MLOps\n",
        "\n",
        "The MLOps discipline sits at the intersection of data science, software engineering, and DevOps. This inherently creates a multidisciplinary challenge, as few individuals are experts in all three.\n",
        "\n",
        "Here are some of the most common skill gaps:\n",
        "\n",
        "- Deep Software Engineering & DevOps Expertise for ML:\n",
        "    - **The Gap:** Many data scientists are proficient in Python for model development but lack the robust software engineering practices (writing production-grade, modular, testable, and maintainable code; understanding design patterns) and DevOps principles (CI/CD, infrastructure as code, containerization, orchestration, monitoring, alerting) required for production systems.\n",
        "    - **Why it exists:** Traditional data science programs often focus heavily on statistics, algorithms, and model building, with less emphasis on software engineering rigor or system operations.\n",
        "    - **Impact:** Leads to \"notebook hell,\" unscalable solutions, manual deployments, and difficult-to-debug systems.\n",
        "\n",
        "- Data Engineering & Data Governance for ML:\n",
        "    - **The Gap:** While data scientists understand data quality, they might lack the deep knowledge of building robust, scalable, and automated data pipelines (ETL/ELT), managing large-scale data lakes/warehouses (BigQuery, Cloud Storage), implementing data versioning (DVC, Vertex AI Feature Store), and enforcing data governance (data quality, lineage, access control) at an enterprise level.\n",
        "    - **Why it exists:** Data engineering is a specialized field. MLOps demands that ML practitioners understand the unique data challenges for models, which go beyond typical business intelligence needs.\n",
        "    - **Impact:** Poor data quality leading to model degradation, lack of reproducibility, compliance risks, and inefficient feature engineering processes.\n",
        "\n",
        "- Cloud-Native MLOps Platform Proficiency (GCP-Specific):\n",
        "    - **The Gap:** Familiarity with the specific tools and services offered by cloud providers for MLOps. For GCP, this means deep knowledge of:\n",
        "       - **Vertex AI (the whole suite):** Vertex AI Workbench, Custom Training, AutoML, Prediction Endpoints, Pipelines, Feature Store, Model Registry, Model Monitoring, Metadata.\n",
        "       - **Related GCP services:** BigQuery, Cloud Storage, Dataflow/Dataproc, Cloud Logging, Cloud Monitoring, Cloud Build, Artifact Registry, IAM.\n",
        "       - **Gen AI specific tools:** Vertex AI's Model Garden, Prompt Engineering best practices for Gemini, fine-tuning techniques, and understanding the nuances of deploying and monitoring LLMs.\n",
        "       -  **Vision AI specific tools:** Knowledge of pre-trained Vision API, AutoML Vision, and building custom vision models.\n",
        "    - **Why it exists:** Cloud platforms are constantly evolving. Many practitioners learn on open-source tools and need to adapt to managed services.\n",
        "    - **Impact:** Underutilization of powerful platform features, inefficient workflows, higher operational costs due to non-optimized cloud usage, and difficulty in scaling.\n",
        "\n",
        "- Model Operationalization and Lifecycle Management:\n",
        "    - **The Gap:** Understanding the entire lifecycle of a model in production, beyond just training. This includes:\n",
        "        - **Model Deployment Strategies:** A/B testing, canary deployments, blue/green deployments.\n",
        "        - **Model Monitoring:** Detecting concept drift, data drift, performance degradation.\n",
        "        - **Automated Retraining and Redeployment:** Setting up triggers and pipelines for continuous model improvement.\n",
        "        - **Model Governance:** Versioning models, tracking lineage, managing artifacts.\n",
        "    - **Why it exists:** Productionizing models is a relatively new challenge compared to traditional software development.\n",
        "    - **Impact:** Stale models, degraded performance, manual firefighting, and a slow pace of innovation.\n",
        "\n",
        "- ML System Design and Architecture:\n",
        "    - **The Gap:** The ability to design end-to-end ML solutions that are scalable, reliable, secure, and cost-efficient. This involves choosing the right services, architecting data flows, and planning for resilience.\n",
        "    - **Why it exists:** Requires a blend of software architecture, cloud architecture, and ML-specific considerations.\n",
        "    Impact: Fragile systems, technical debt, and difficulty in scaling AI initiatives.\n",
        "\n",
        "- AI Ethics, Bias, and Responsible AI:\n",
        "    - **The Gap:** While growing in importance, many practitioners still lack a deep understanding of how to proactively identify and mitigate bias in data and models, ensure fairness, privacy, and transparency, and adhere to ethical guidelines and regulations (like GDPR, HIPAA, or emerging AI acts).\n",
        "    - **Why it exists:** A newer field, and often not a core component of traditional ML education.\n",
        "    - **Impact:** Reputational damage, legal/compliance issues, and models that perpetuate societal biases. This is particularly relevant for sensitive applications of Vision AI and Gemini."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bridging the Skill Gaps\n",
        "\n",
        "Addressing these gaps requires a multi-pronged approach:\n",
        "- Cross-Functional Collaboration:\n",
        "    - **Break Down Silos:** Encourage data scientists, ML engineers, software engineers, and DevOps engineers to work closely together.\n",
        "    - **Shared Ownership:** Promote shared responsibility for the entire ML lifecycle, from data to deployment.\n",
        "    - **Knowledge Sharing:** Regular brown bag sessions, internal workshops, and documentation.\n",
        "\n",
        "- Continuous Learning and Upskilling:\n",
        "    - **Formal Training:** Leverage platforms like Google Cloud Skills Boost, Coursera, edX, and others that offer dedicated MLOps, Data Engineering, and cloud-specific certifications (e.g., Google Cloud Professional Machine Learning Engineer).\n",
        "    - **Hands-on Labs and Projects:** Practical experience with Vertex AI services is invaluable. Qwiklabs (part of Google Cloud Skills Boost) provides excellent hands-on opportunities.\n",
        "    - **Internal Training Programs:** Develop customized training tailored to your organization's tech stack and specific MLOps challenges.\n",
        "    - **Mentorship:** Pair experienced engineers with data scientists eager to learn production best practices.\n",
        "\n",
        "- Standardization and Automation:\n",
        "    - **MLOps Platforms:** Adopt a comprehensive MLOps platform (like Vertex AI) to standardize workflows, automate repetitive tasks, and enforce best practices.\n",
        "    - **Templates and Blueprints:** Create reusable templates for pipelines, model deployment, and monitoring configurations. This reduces the need for every team member to be an expert in everything from scratch.\n",
        "    - **Infrastructure as Code (IaC):** Use tools like Terraform or Pulumi to define and provision your GCP MLOps infrastructure consistently.\n",
        "\n",
        "- Hiring Strategy:\n",
        "    - **Look for Hybrid Roles:** Seek out individuals with a blend of data science and engineering skills (e.g., \"MLOps Engineer\" or \"Applied Scientist\" roles that emphasize production).\n",
        "    - **Value Learnability:** Given the rapid pace of change, prioritize candidates who demonstrate a strong ability to learn new tools and adapt to evolving technologies over strict adherence to a specific tool list.\n",
        "    - **Team Diversity:** Build teams with diverse skill sets that complement each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example Training Roadmaps (Conceptual)\n",
        "\n",
        "For a Data Scientist looking to become more MLOps-capable on GCP:\n",
        "\n",
        "- **Fundamentals:** Python for Production, Software Engineering Best Practices (testing, modularity), Git.\n",
        "- **Data Engineering:** SQL (BigQuery), Dataflow/Beam concepts, understanding ETL/ELT, Vertex AI Feature Store.\n",
        "- **Cloud Basics:** GCP fundamentals, IAM, Cloud Storage.\n",
        "- **Vertex AI Essentials:** Vertex AI Workbench, Custom Training, Endpoints, Model Registry.\n",
        "- **MLOps Core:** Vertex AI Pipelines, Vertex AI Model Monitoring, Vertex AI Metadata.\n",
        "- **Specialization:** Prompt Engineering (for LLMs), understanding Vision AI services.\n",
        "\n",
        "For a Software Engineer/DevOps Engineer looking to get into MLOps on GCP:\n",
        "\n",
        "- **ML/Data Science Fundamentals:** Core ML concepts, model lifecycle, common algorithms, evaluation metrics.\n",
        "- **Python for ML:** Pandas, NumPy, Scikit-learn, TensorFlow/PyTorch basics.\n",
        "- **GCP Deep Dive:** Kubernetes (GKE), Docker, Cloud Build, Terraform/Pulumi, Cloud Logging, Cloud Monitoring, Network configuration.\n",
        "- **Vertex AI Essentials:** Vertex AI Pipelines, Custom Training, Endpoints, Model Monitoring.\n",
        "- **Data Engineering Concepts:** How ML data pipelines differ from traditional ones, BigQuery usage.\n",
        "- **Specialization:** Model explainability (Vertex Explainable AI), MLOps security.\n",
        "\n",
        "Bridging skill gaps in MLOps is not just about individuals learning new tools; it's about fostering a culture of continuous learning, cross-functional collaboration, and strategic investment in platforms and automation. This ultimately leads to more reliable, scalable, and impactful ML systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Tooling Proliferation and Integration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Challenge of Tooling Proliferation and Integration\n",
        "\n",
        "- Sheer Volume of Tools:\n",
        "    - **Across the ML Lifecycle:** There are tools for data versioning, feature stores, experiment tracking, model training, model serving, monitoring, explainability, pipeline orchestration, data validation, artifact management, and more.\n",
        "    - **Open Source vs. Cloud Native vs. Commercial:** You have a choice between popular open-source frameworks (MLflow, DVC, Airflow, Kubeflow, PyTorch, TensorFlow), comprehensive cloud-native platforms (Vertex AI, SageMaker, Azure ML), and specialized commercial offerings.\n",
        "    - **Specialized AI:** With Vision AI, you might use OpenCV, TensorFlow Hub for pre-trained models, specific image annotation tools. With Gemini, you're dealing with prompt engineering platforms, fine-tuning tools, and potentially different model serving patterns for LLMs.\n",
        "\n",
        "- Integration Complexity:\n",
        "    - **\"Stitching Together\":** Even within a single cloud provider like GCP, while Vertex AI aims to be an end-to-end platform, you'll still be integrating it with BigQuery for data, Cloud Storage for artifacts, Cloud Build for CI/CD, Artifact Registry for Docker images, Cloud Logging for logs, and Cloud Monitoring for metrics. Outside of GCP, you might be integrating with on-prem data sources, external APIs, or other cloud environments.\n",
        "    - **API Inconsistencies:** Different tools and services have different APIs, authentication methods, and data formats, requiring custom glue code and extensive configuration.\n",
        "    - **Dependency Management:** Managing conflicting dependencies between different libraries and tools within your environment (e.g., specific versions of TensorFlow, PyTorch, or utility libraries) becomes a nightmare.\n",
        "    - **Orchestration Overhead:** While tools like Vertex AI Pipelines (or Airflow, Kubeflow Pipelines) help orchestrate workflows, defining and maintaining these complex pipelines across disparate tools still requires significant effort.\n",
        "\n",
        "- Vendor Lock-in vs. Flexibility:\n",
        "    - Choosing a fully integrated platform (like Vertex AI) offers seamless integration and reduced overhead but might limit flexibility for highly specialized use cases or multi-cloud strategies.\n",
        "    - Choosing a best-of-breed open-source approach offers flexibility but introduces the heavy burden of integration and maintenance. Finding the right balance is hard.\n",
        "\n",
        "- Skill Development and Team Fragmentation:\n",
        "    - **Learning Curve:** Each new tool introduces a learning curve for your team. Keeping up with updates and best practices across numerous tools is challenging.\n",
        "    - **Specialization Silos:** Teams might become overly specialized in a few tools, making cross-functional collaboration difficult (e.g., data scientists prefer notebooks and MLflow, while DevOps engineers prefer Kubernetes and Terraform, and ML engineers need to bridge the gap).\n",
        "\n",
        "- Maintainability and Technical Debt:\n",
        "    - **Broken Pipelines:** A small change in one tool's API or a dependency update can break an entire integrated pipeline.\n",
        "    - **Custom Glue Code:** The more custom integration code you write, the higher your technical debt and maintenance burden.\n",
        "    - **Security Concerns:** Integrating multiple tools, especially open-source ones, can introduce new security vulnerabilities if not properly managed and updated.\n",
        "\n",
        "- Cost and Resource Management:\n",
        "    - Managing multiple tools (licenses, compute resources, storage) can become complex and lead to unexpected costs. Optimization becomes harder when tools aren't natively integrated.\n",
        "\n",
        "### Strategies to Address Tooling Proliferation and Integration\n",
        "\n",
        "- Standardization and Centralization (Where Possible):\n",
        "    - **Choose a Core Platform:** For GCP users, Vertex AI should be your primary MLOps platform. It's designed to be end-to-end and provides managed services for most MLOps stages (data management with Feature Store, training, deployment, monitoring, experiment tracking, pipelines). This significantly reduces the \"stitching\" effort.\n",
        "    - **Define a \"Golden Path\":** Establish preferred tools and best practices for common tasks (e.g., \"All experiment tracking will use Vertex AI Experiments,\" \"All data versioning will leverage GCS object versioning and BigQuery snapshots, complemented by Vertex AI Metadata\").\n",
        "    - **Managed Services First:** Prioritize GCP's managed services over self-managed open-source tools where appropriate, as they reduce operational overhead (e.g., Vertex AI Pipelines vs. self-managed Airflow on GKE).\n",
        "\n",
        "- Modularization and APIs:\n",
        "    - **API-First Design:** Encapsulate functionalities within APIs (e.g., a model serving API) so that consuming applications don't need to know the underlying ML framework.\n",
        "    - **Reusable Components:** Develop reusable code components and pipeline templates for common tasks (e.g., a standard data loading module, a generic model evaluation step) that can be shared across projects. Vertex AI Pipelines custom components are excellent for this.\n",
        "    - **Containerization (Docker & Artifact Registry):** Package your code, dependencies, and environments into Docker containers. This ensures consistency and simplifies deployment across different environments. Store them in Artifact Registry.\n",
        "\n",
        "- Robust CI/CD for MLOps:\n",
        "    - **Automate Everything:** Use Cloud Build to automate testing, building, and deploying your ML pipelines and models.\n",
        "    - **Version Control:** Strictly version control all code, configurations (including pipeline definitions), and environment definitions.\n",
        "    - **Infrastructure as Code (IaC):** Use Terraform or Pulumi to define and deploy your GCP resources (Vertex AI endpoints, BigQuery datasets, GCS buckets) programmatically. This ensures consistent environments.\n",
        "\n",
        "- Strong Governance and Documentation:\n",
        "    - **Tooling Strategy Document:** Create a clear document outlining your organization's chosen MLOps tools, their purpose, how they integrate, and best practices for using them.\n",
        "    - **Decision Matrix:** For new tools, create a decision matrix that evaluates them against criteria like: existing ecosystem integration, maturity, community support, cost, and skill requirements.\n",
        "    - **Comprehensive Documentation:** Document all pipelines, data schemas, API specifications, and monitoring configurations.\n",
        "\n",
        "- Talent Development and Training:\n",
        "    - **Targeted Training:** Provide specific training on your chosen GCP MLOps stack.\n",
        "    - **Cross-Training:** Encourage team members to learn about tools used by other disciplines (e.g., data scientists learning basic Terraform, engineers understanding ML lifecycle concepts).\n",
        "    - **Community of Practice:** Foster an internal community of practice around MLOps to share knowledge and solve integration challenges collectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simple Conceptual Code Example (No direct execution, but a template)\n",
        "\n",
        "This snippet illustrates the idea of how different GCP services integrate conceptually within an MLOps pipeline, rather than showing a runnable integration. The \"glue\" is often handled by Vertex AI Pipelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is a conceptual template to illustrate tooling integration points\n",
        "# It's not executable as-is without a full Vertex AI Pipeline setup.\n",
        "\n",
        "# --- MLOps Pipeline Definition (Conceptual, often using Vertex AI Pipelines SDK) ---\n",
        "# import kfp # Kubeflow Pipelines SDK for Vertex AI Pipelines\n",
        "# from google_cloud_pipeline_components.aiplatform import (\n",
        "#     Endpoint, ModelUploadOp, ModelDeployOp, ModelMonitorOp\n",
        "# )\n",
        "# from google_cloud_pipeline_components.types import artifact_types\n",
        "# from google_cloud_pipeline_components.v1 import bigquery as bq\n",
        "# from kfp.v2 import dsl\n",
        "# from kfp.v2.dsl import (\n",
        "#     component, Input, Output, Metrics, Dataset, Model, Artifact,\n",
        "#     ClassificationMetrics, GCSPath\n",
        "# )\n",
        "\n",
        "# --- 1. Data Ingestion & Validation (Leveraging BigQuery, Cloud Storage, Data Catalog) ---\n",
        "# Goal: Get data from BigQuery, validate, store in GCS.\n",
        "\n",
        "# @component(\n",
        "#     packages_to_install=[\"pandas\", \"pyarrow\", \"google-cloud-bigquery\", \"google-cloud-storage\", \"great_expectations\"],\n",
        "#     base_image=\"python:3.9\"\n",
        "# )\n",
        "# def ingest_and_validate_data(\n",
        "#     project_id: str,\n",
        "#     bq_table_id: str,\n",
        "#     gcs_output_path: GCSPath,\n",
        "#     validation_results_path: Output[Artifact] # Output artifact for validation report\n",
        "# ):\n",
        "#     # BigQuery Client for data fetching\n",
        "#     # from google.cloud import bigquery\n",
        "#     # client = bigquery.Client(project=project_id)\n",
        "#     # query = f\"SELECT * FROM `{bq_table_id}`\"\n",
        "#     # df = client.query(query).to_dataframe()\n",
        "\n",
        "#     # Data Validation (e.g., using Great Expectations)\n",
        "#     # context = DataContext()\n",
        "#     # batch_request = RuntimeBatchRequest(...)\n",
        "#     # checkpoint = Checkpoint(name=\"my_checkpoint\", site_names=[\"my_docs_site\"], batch_request=batch_request)\n",
        "#     # results = checkpoint.run()\n",
        "#     # results_path.path = f\"{gcs_output_path}/validation_results.json\"\n",
        "#     # save_results(results, results_path.path)\n",
        "\n",
        "#     # Store validated data to GCS\n",
        "#     # df.to_parquet(gcs_output_path + \"/validated_data.parquet\", index=False)\n",
        "#     logging.info(f\"Data ingested from {bq_table_id} and validated. Stored at {gcs_output_path}\")\n",
        "\n",
        "# --- 2. Feature Engineering (Leveraging Vertex AI Feature Store, Dataflow/Pandas) ---\n",
        "# Goal: Transform raw data into features, store in Feature Store or pass directly.\n",
        "\n",
        "# @component(\n",
        "#     packages_to_install=[\"pandas\", \"scikit-learn\", \"google-cloud-aiplatform\"],\n",
        "#     base_image=\"python:3.9\"\n",
        "# )\n",
        "# def feature_engineering(\n",
        "#     input_gcs_path: Input[Dataset],\n",
        "#     feature_store_id: str, # Optional: if using Feature Store\n",
        "#     output_features_gcs_path: GCSPath\n",
        "# ):\n",
        "#     # Load data from GCS\n",
        "#     # df = pd.read_parquet(input_gcs_path.path + \"/validated_data.parquet\")\n",
        "\n",
        "#     # Perform feature transformations\n",
        "#     # df['new_feature'] = df['existing_feature'] * 2\n",
        "\n",
        "#     # If using Vertex AI Feature Store:\n",
        "#     # from google.cloud.aiplatform_v1.services import featurestore_online_serving_service\n",
        "#     # aiplatform.init(project=project_id, location=region)\n",
        "#     # entity_type = aiplatform.Featurestore(feature_store_id).get_entity_type(\"my_entity_type\")\n",
        "#     # entity_type.ingest_from_dataframe(df, ...)\n",
        "\n",
        "#     # Save processed features to GCS for training\n",
        "#     # df.to_parquet(output_features_gcs_path + \"/features.parquet\", index=False)\n",
        "#     logging.info(f\"Features engineered. Stored at {output_features_gcs_path}\")\n",
        "\n",
        "# --- 3. Model Training (Leveraging Vertex AI Custom Training, Managed Datasets) ---\n",
        "# Goal: Train a model using prepared features, log metrics, save model artifact.\n",
        "\n",
        "# @component(\n",
        "#     packages_to_install=[\"scikit-learn\", \"tensorflow\", \"google-cloud-aiplatform\"],\n",
        "#     base_image=\"gcr.io/cloud-aiplatform/training/tf-cpu.2-12.py310\" # Example TF image\n",
        "# )\n",
        "# def train_model(\n",
        "#     features_gcs_path: Input[Dataset],\n",
        "#     model_gcs_path: Output[Model], # Output artifact for the trained model\n",
        "#     metrics: Output[Metrics]\n",
        "# ):\n",
        "#     # Load features\n",
        "#     # X, y = load_features_from_gcs(features_gcs_path.path)\n",
        "\n",
        "#     # Train model (e.g., TensorFlow, PyTorch, Scikit-learn)\n",
        "#     # model = create_and_train_model(X, y)\n",
        "\n",
        "#     # Log metrics to Vertex AI Experiments (integrated via SDK)\n",
        "#     # metrics.log_metric(\"accuracy\", 0.85)\n",
        "#     # metrics.log_metric(\"loss\", 0.15)\n",
        "\n",
        "#     # Save model artifact to GCS\n",
        "#     # model.save(model_gcs_path.path)\n",
        "#     logging.info(f\"Model trained and saved to {model_gcs_path.path}\")\n",
        "\n",
        "# --- 4. Model Deployment (Leveraging Vertex AI Prediction Endpoint, Artifact Registry) ---\n",
        "# Goal: Register model, create endpoint, deploy model version.\n",
        "\n",
        "# @component(\n",
        "#     packages_to_install=[\"google-cloud-aiplatform\"],\n",
        "#     base_image=\"python:3.9\"\n",
        "# )\n",
        "# def deploy_model(\n",
        "#     model: Input[Model],\n",
        "#     project_id: str,\n",
        "#     model_display_name: str,\n",
        "#     endpoint_display_name: str,\n",
        "#     serving_container_image_uri: str # From Artifact Registry\n",
        "# ):\n",
        "#     # from google.cloud import aiplatform\n",
        "#     # aiplatform.init(project=project_id, location=region)\n",
        "\n",
        "#     # Upload model to Vertex AI Model Registry\n",
        "#     # uploaded_model = aiplatform.Model.upload(\n",
        "#     #     display_name=model_display_name,\n",
        "#     #     artifact_uri=model.uri,\n",
        "#     #     serving_container_image_uri=serving_container_image_uri\n",
        "#     # )\n",
        "\n",
        "#     # Create or get endpoint\n",
        "#     # try:\n",
        "#     #     endpoint = aiplatform.Endpoint(endpoint_name=endpoint_display_name)\n",
        "#     # except ValueError:\n",
        "#     #     endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)\n",
        "\n",
        "#     # Deploy model to endpoint\n",
        "#     # endpoint.deploy(\n",
        "#     #     model=uploaded_model,\n",
        "#     #     deployed_model_display_name=model_display_name + \"_deployed\",\n",
        "#     #     machine_type=\"n1-standard-4\",\n",
        "#     #     min_replica_count=1,\n",
        "#     #     max_replica_count=1\n",
        "#     # )\n",
        "#     logging.info(f\"Model {model_display_name} deployed to endpoint {endpoint_display_name}.\")\n",
        "\n",
        "# --- 5. Model Monitoring (Leveraging Vertex AI Model Monitoring) ---\n",
        "# Goal: Configure automated monitoring for data and prediction drift, and performance.\n",
        "\n",
        "# @component(\n",
        "#     packages_to_install=[\"google-cloud-aiplatform\"],\n",
        "#     base_image=\"python:3.9\"\n",
        "# )\n",
        "# def configure_model_monitoring(\n",
        "#     project_id: str,\n",
        "#     model_id: str, # ID of the deployed model\n",
        "#     endpoint_id: str, # ID of the endpoint\n",
        "#     monitoring_job_display_name: str,\n",
        "#     bq_training_data_source: str # BigQuery table used for training baseline\n",
        "# ):\n",
        "#     # from google.cloud import aiplatform\n",
        "#     # aiplatform.init(project=project_id, location=region)\n",
        "\n",
        "#     # Configure Vertex AI Model Monitoring Job\n",
        "#     # model_monitoring_job = aiplatform.ModelMonitoringJob.create(\n",
        "#     #     display_name=monitoring_job_display_name,\n",
        "#     #     model=model_id,\n",
        "#     #     endpoint=endpoint_id,\n",
        "#     #     location=region,\n",
        "#     #     schedule_config=aiplatform.models.ModelMonitoringJob.ScheduleConfig(\n",
        "#     #         monitor_interval=timedelta(hours=1)\n",
        "#     #     ),\n",
        "#     #     model_monitoring_alert_config=aiplatform.models.ModelMonitoringJob.ModelMonitoringAlertConfig(\n",
        "#     #         email_alert_config=aiplatform.models.ModelMonitoringJob.ModelMonitoringAlertConfig.EmailAlertConfig(\n",
        "#     #             user_emails=[\"your_email@example.com\"]\n",
        "#     #         )\n",
        "#     #     ),\n",
        "#     #     model_monitoring_objective_config=aiplatform.models.ModelMonitoringJob.ModelMonitoringObjectiveConfig(\n",
        "#     #         training_dataset=aiplatform.models.ModelMonitoringJob.ModelMonitoringObjectiveConfig.TrainingDataset(\n",
        "#     #             bigquery_source=aiplatform.models.ModelMonitoringJob.ModelMonitoringObjectiveConfig.TrainingDataset.BigQuerySource(\n",
        "#     #                 uri=f\"bq://{bq_training_data_source}\"\n",
        "#     #             ),\n",
        "#     #             target_field=\"target\" # The column your model predicts\n",
        "#     #         ),\n",
        "#     #         # ... other objectives like prediction drift, feature attribution drift\n",
        "#     #     )\n",
        "#     # )\n",
        "#     logging.info(f\"Model monitoring job '{monitoring_job_display_name}' configured.\")\n",
        "\n",
        "# --- Define the MLOps Pipeline ---\n",
        "# @dsl.pipeline(\n",
        "#     name=\"customer-churn-mlops-pipeline\",\n",
        "#     description=\"End-to-end MLOps pipeline for customer churn prediction.\"\n",
        "# )\n",
        "# def customer_churn_pipeline(\n",
        "#     project_id: str = \"your-gcp-project-id\",\n",
        "#     region: str = \"us-central1\",\n",
        "#     bq_source_table: str = \"your_project.your_dataset.raw_customer_data\",\n",
        "#     gcs_data_bucket: str = \"gs://your-data-bucket/churn\",\n",
        "#     model_display_name: str = \"churn-prediction-model\",\n",
        "#     endpoint_display_name: str = \"churn-prediction-endpoint\",\n",
        "#     serving_image_uri: str = \"us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-12:latest\"\n",
        "# ):\n",
        "#     # Create tasks and define dependencies\n",
        "#     ingest_task = ingest_and_validate_data(\n",
        "#         project_id=project_id,\n",
        "#         bq_table_id=bq_source_table,\n",
        "#         gcs_output_path=f\"{gcs_data_bucket}/raw_validated_data\"\n",
        "#     )\n",
        "\n",
        "#     feature_eng_task = feature_engineering(\n",
        "#         input_gcs_path=ingest_task.outputs[\"gcs_output_path\"],\n",
        "#         output_features_gcs_path=f\"{gcs_data_bucket}/processed_features\"\n",
        "#     )\n",
        "\n",
        "#     train_model_task = train_model(\n",
        "#         features_gcs_path=feature_eng_task.outputs[\"output_features_gcs_path\"]\n",
        "#     )\n",
        "\n",
        "#     deploy_model_task = deploy_model(\n",
        "#         model=train_model_task.outputs[\"model\"],\n",
        "#         project_id=project_id,\n",
        "#         model_display_name=model_display_name,\n",
        "#         endpoint_display_name=endpoint_display_name,\n",
        "#         serving_container_image_uri=serving_image_uri\n",
        "#     )\n",
        "\n",
        "#     monitor_model_task = configure_model_monitoring(\n",
        "#         project_id=project_id,\n",
        "#         model_id=deploy_model_task.outputs[\"model_id\"], # Get ID from deployment\n",
        "#         endpoint_id=deploy_model_task.outputs[\"endpoint_id\"], # Get ID from deployment\n",
        "#         monitoring_job_display_name=f\"{model_display_name}-monitor\",\n",
        "#         bq_training_data_source=bq_source_table # Use the original training data for baseline\n",
        "#     )\n",
        "\n",
        "# # To run this in a Jupyter Notebook:\n",
        "# # from google.cloud import aiplatform\n",
        "# # aiplatform.init(project=\"your-gcp-project-id\", location=\"us-central1\")\n",
        "# # job = aiplatform.PipelineJob(\n",
        "# #     display_name=\"churn-prediction-pipeline-run\",\n",
        "# #     template_path=kfp.compiler.Compiler().compile(customer_churn_pipeline),\n",
        "# #     pipeline_root=f\"gs://your-pipeline-artifacts-bucket/pipeline_root\",\n",
        "# #     enable_caching=False\n",
        "# # )\n",
        "# # job.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Key Takeaways from the Conceptual Template:\n",
        "- **Vertex AI Pipelines as the Orchestrator:** This is the central hub for integrating different services. Each @component represents a step that can utilize specific GCP services or custom code.\n",
        "- **Input/Output Artifacts (Dataset, Model, Artifact):** These define the handoff points between different pipeline steps. Vertex AI Metadata automatically tracks the lineage of these artifacts.\n",
        "\n",
        "- Service Integration (Implicit):\n",
        "    - ingest_and_validate_data would use google-cloud-bigquery and google-cloud-storage client libraries.\n",
        "    - feature_engineering might interact with google-cloud-aiplatform for Feature Store.\n",
        "    - train_model leverages Vertex AI's managed training infrastructure.\n",
        "    - deploy_model uses Vertex AI Prediction Endpoints and relies on Artifact Registry for the serving container image.\n",
        "    - configure_model_monitoring directly calls Vertex AI Model Monitoring APIs.\n",
        "\n",
        "- **Reduced \"Glue Code\":** While you write Python code within each component, Vertex AI Pipelines handles the complex boilerplate of managing VMs, installing dependencies, passing artifacts between steps, and logging.\n",
        "- **Focus on the \"ML\" Logic:** The aim is to allow engineers to focus more on the ML-specific logic (data cleaning, feature engineering, model training) within the component, rather than the operational complexities of stitching systems together.\n",
        "\n",
        "By strategically adopting integrated platforms like Vertex AI, establishing clear standards, and automating workflows, organizations can mitigate the challenges of tooling proliferation and build more robust, scalable, and manageable MLOps systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Cost Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Challenge of Cost Management in MLOps\n",
        "\n",
        "ML workloads are notoriously resource-intensive. Training large models (especially LLMs like Gemini or complex Vision AI models) can consume vast amounts of compute (CPUs, GPUs, TPUs) and storage. Inference can also add up, particularly with high-volume, low-latency requirements.\n",
        "\n",
        "Here's why cost management is a significant challenge:\n",
        "\n",
        "- Variable and Bursty Workloads:\n",
        "    - **Experimentation:** Data scientists constantly spin up and tear down environments, run multiple experiments in parallel, and might forget to shut down resources.\n",
        "    - **Training:** Training jobs can range from short, CPU-bound tasks to multi-day, multi-GPU/TPU behemoths. These are not always continuous, making steady-state budgeting difficult.\n",
        "    - **Inference:** Production endpoints might experience highly variable traffic, leading to under- or over-provisioning if not managed dynamically.\n",
        "\n",
        "- Resource Intensity of AI:\n",
        "    - **Accelerators:** GPUs and TPUs are powerful but expensive. Maximizing their utilization is critical.\n",
        "    - **Storage:** Storing vast amounts of raw data, processed features, model checkpoints, and logs can accrue significant storage costs (especially with versioning and backups).\n",
        "    - **Networking:** Large data transfers between regions or services can incur egress charges.\n",
        "\n",
        "- Lack of Visibility and Granularity:\n",
        "    - Identifying which specific experiment, model, or team is consuming the most resources can be challenging in a shared environment.\n",
        "    - Attributing costs accurately to projects, departments, or even individual features can be difficult without proper tagging and accounting.\n",
        "\n",
        "- Idle Resources:\n",
        "    - Often, compute instances (VMs, Jupyter notebooks/Vertex AI Workbench instances) are left running when not actively in use, leading to wasted spend.\n",
        "    - Unused storage buckets, old model versions, or dormant data pipelines can also contribute to \"zombie costs.\"\n",
        "\n",
        "- Complexity of Pricing Models:\n",
        "    - GCP pricing models can be complex, with nuances for different services (e.g., storage tiers, network egress, specialized AI API calls, per-second billing, sustained use discounts). Understanding these is key to optimization.\n",
        "\n",
        "- \"Black Box\" Consumption for Advanced Services:\n",
        "    With services like Vertex AI AutoML, Vision AI APIs, or Gemini APIs, you're paying for managed services, and it can be harder to directly control or optimize the underlying compute used by the vendor for your specific request. You pay per prediction, per image processed, per token, etc. The focus shifts to optimizing usage (e.g., batching requests, caching, fine-tuning smaller models)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategies for Cost Management on GCP MLOps\n",
        "\n",
        "Leverage Managed Services Wisely (and understand their pricing):\n",
        "- **Vertex AI:** Use Vertex AI Training for managed, ephemeral training jobs (they spin up, run, and shut down automatically). Use Vertex AI Prediction Endpoints with auto-scaling to match inference traffic.\n",
        "- **Vertex AI Feature Store:** While it has a cost, centralizing features can reduce redundant compute for feature engineering across multiple models.\n",
        "- **Vision AI / Gemini APIs:** For pre-trained models, you pay per unit (image, token). Optimize by:\n",
        "    - **Batching requests:** Send multiple items in a single API call if supported.\n",
        "    - **Caching:** Store API responses for frequently requested identical inputs.\n",
        "    - **Filtering:** Only send data that absolutely needs AI processing.\n",
        "    - **Fine-tuning smaller models:** Sometimes, fine-tuning a smaller model can be cheaper for a specific task than using a massive foundation model for every single inference.\n",
        "- **BigQuery:** Optimize queries to reduce bytes processed. Use partitioning, clustering, and materialized views. Leverage BigQuery ML for in-database model training to reduce data movement.\n",
        "- **Cloud Storage:** Choose the right storage class (Standard, Nearline, Coldline, Archive) based on access frequency. Implement lifecycle policies to automatically move older data to colder tiers or delete it.\n",
        "\n",
        "Optimize Compute Resources:\n",
        "- **Right-sizing Instances:** Don't just pick the largest GPU. Experiment to find the optimal VM type and accelerator for your training job. Sometimes, a slightly smaller GPU used efficiently is better.\n",
        "- **Spot Instances/Preemptible VMs:** For fault-tolerant training jobs (e.g., if you have robust checkpointing), use Spot instances or Preemptible VMs (available with Vertex AI Custom Training) to save up to 80-90% on compute costs.\n",
        "- **Auto-scaling:** Configure auto-scaling for Vertex AI Prediction Endpoints to ensure you only pay for the resources needed to handle current traffic.\n",
        "- **Scheduled Shutdowns:** For Vertex AI Workbench Notebook instances (or regular Compute Engine VMs), implement automated shutdown policies for idle resources.\n",
        "- **Kubernetes (GKE):** If you're self-managing ML workloads on GKE, use Horizontal Pod Autoscalers and Cluster Autoscalers to dynamically adjust resources.\n",
        "\n",
        "Data Storage and Transfer Optimization:\n",
        "- **Lifecycle Policies:** As mentioned above, automate data tiering in GCS.\n",
        "- **Data Archiving/Deletion:** Regularly review and delete unused or outdated datasets, model checkpoints, and logs.\n",
        "- **Regionality:** Store data in the same region as your compute resources to minimize network transfer costs.\n",
        "- **Compression:** Compress data files (e.g., Parquet, TFRecord) before storing them in GCS or processing them in Dataflow.\n",
        "\n",
        "Implement Strong Governance and Visibility:\n",
        "- **Resource Tagging/Labels:** Use GCP Labels extensively (e.g., project:my-ml-app, team:data-science, environment:dev, owner:john-doe, experiment_id:xyz). This allows you to filter and group costs in Cloud Billing reports.\n",
        "- **Cloud Billing Reports & Dashboards:** Regularly review your GCP billing reports. Set up custom dashboards in Cloud Monitoring to visualize spending per service, project, or label.\n",
        "- **Cost Management Tools:** Use Cloud Billing Budgets and Alerts to get notified when spending approaches predefined thresholds. Explore GCP's Cost Management tools for recommendations.\n",
        "- **Resource Hierarchy:** Organize your GCP projects and folders logically to align with organizational structure for easier cost allocation.\n",
        "- **Audit Logs:** Review Cloud Audit Logs to understand who is creating/modifying resources.\n",
        "\n",
        "Build Cost-Aware MLOps Practices:\n",
        "- **Automated Cleanup:** Design your Vertex AI Pipelines to automatically clean up temporary artifacts, GCS buckets, or unused endpoints after successful runs or failures.\n",
        "- **Smaller Models First:** Start with smaller, less resource-intensive models during initial experimentation. Only scale up to larger models/accelerators when necessary.\n",
        "- **Batch Inference:** For non-real-time predictions, prefer batch inference (e.g., via Dataflow or Vertex AI Batch Prediction) over real-time endpoints, as it's often more cost-efficient due to better resource utilization.\n",
        "- **Model Quantization/Pruning:** Explore techniques to reduce model size and complexity, leading to cheaper inference.\n",
        "- **Data Sampling:** During early development and experimentation, use smaller samples of your data to reduce training time and cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conceptual Cost Management Snippet (Jupyter Notebook)\n",
        "\n",
        "This isn't code that directly manages costs, but rather code you'd include in your notebooks or pipelines to ensure cost visibility and adherence to best practices for resource usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "# --- Configuration for Cost Management ---\n",
        "GCP_PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\", \"your-gcp-project-id\")\n",
        "GCP_REGION = os.getenv(\"GCP_REGION\", \"us-central1\")\n",
        "# Ensure these labels are consistently applied to all GCP resources you provision!\n",
        "COMMON_GCP_LABELS = {\n",
        "    \"project_name\": \"customer-churn-prediction\",\n",
        "    \"team\": \"data-science\",\n",
        "    \"environment\": \"dev\", # or 'prod', 'staging', 'qa'\n",
        "    \"owner\": \"your-gcp-username\", # e.g., 'john-doe'\n",
        "    \"ml_phase\": \"experimentation\" # e.g., 'training', 'inference', 'data_prep'\n",
        "}\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "print(f\"--- Starting MLOps Cost Management Awareness ---\")\n",
        "logging.info(f\"Current GCP Project: {GCP_PROJECT_ID}, Region: {GCP_REGION}\")\n",
        "logging.info(f\"Common GCP Labels for Cost Tracking: {COMMON_GCP_LABELS}\")\n",
        "\n",
        "# --- Helper Function: Log Resource Usage Parameters ---\n",
        "def log_compute_resource_params(task_name, machine_type, accelerator_type=None, accelerator_count=None, is_preemptible=False):\n",
        "    \"\"\"Logs the chosen compute resources for a specific task.\"\"\"\n",
        "    resource_info = {\n",
        "        \"task\": task_name,\n",
        "        \"machine_type\": machine_type,\n",
        "        \"accelerator_type\": accelerator_type,\n",
        "        \"accelerator_count\": accelerator_count,\n",
        "        \"is_preemptible\": is_preemptible,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "    logging.info(f\"Compute Resource Parameters Logged:\\n{json.dumps(resource_info, indent=2)}\")\n",
        "    # In a real pipeline, this info would be logged to Vertex AI Metadata or Cloud Logging\n",
        "    # and tagged with appropriate labels.\n",
        "\n",
        "# --- Helper Function: Log Storage Usage Best Practices ---\n",
        "def log_storage_best_practice(storage_path, purpose, recommended_class=\"STANDARD\", lifecycle_policy_planned=True):\n",
        "    \"\"\"Logs storage usage intention and best practice adherence.\"\"\"\n",
        "    storage_info = {\n",
        "        \"path\": storage_path,\n",
        "        \"purpose\": purpose,\n",
        "        \"recommended_storage_class\": recommended_class,\n",
        "        \"lifecycle_policy_planned\": lifecycle_policy_planned,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "    logging.info(f\"Storage Best Practice Logged:\\n{json.dumps(storage_info, indent=2)}\")\n",
        "    # In a real pipeline, you'd verify these GCS bucket properties via SDK calls.\n",
        "\n",
        "\n",
        "# --- Example Usage in a Jupyter Notebook / Pipeline Step ---\n",
        "\n",
        "# Scenario 1: Model Training Job\n",
        "logging.info(\"\\n--- Configuring Model Training Job (Cost-Awareness) ---\")\n",
        "# When defining your Vertex AI Custom Training Job:\n",
        "TRAINING_MACHINE_TYPE = \"n1-standard-8\"\n",
        "TRAINING_ACCELERATOR_TYPE = \"NVIDIA_TESLA_V100\"\n",
        "TRAINING_ACCELERATOR_COUNT = 1\n",
        "USE_PREEMPTIBLE_VM = True # Significantly reduce costs for fault-tolerant jobs\n",
        "\n",
        "log_compute_resource_params(\n",
        "    task_name=\"model_training_churn_v1\",\n",
        "    machine_type=TRAINING_MACHINE_TYPE,\n",
        "    accelerator_type=TRAINING_ACCELERATOR_TYPE,\n",
        "    accelerator_count=TRAINING_ACCELERATOR_COUNT,\n",
        "    is_preemptible=USE_PREEMPTIBLE_VM\n",
        ")\n",
        "if USE_PREEMPTIBLE_VM:\n",
        "    logging.warning(\"Training job configured to use Preemptible VMs. Ensure your training script handles preemption!\")\n",
        "\n",
        "# Scenario 2: Data Storage for Raw and Processed Features\n",
        "logging.info(\"\\n--- Configuring Data Storage (Cost-Awareness) ---\")\n",
        "RAW_DATA_GCS_PATH = f\"gs://{GCP_PROJECT_ID}-raw-data/churn/2024-06-01/\"\n",
        "PROCESSED_DATA_GCS_PATH = f\"gs://{GCP_PROJECT_ID}-features/churn/v1/\"\n",
        "MODEL_ARTIFACTS_GCS_PATH = f\"gs://{GCP_PROJECT_ID}-model-artifacts/churn/v1/\"\n",
        "\n",
        "log_storage_best_practice(\n",
        "    storage_path=RAW_DATA_GCS_PATH,\n",
        "    purpose=\"Raw Ingested Data\",\n",
        "    recommended_class=\"COLDLINE\", # If rarely accessed after initial processing\n",
        "    lifecycle_policy_planned=True # Should have a policy to move older data to ARCHIVE or delete\n",
        ")\n",
        "log_storage_best_practice(\n",
        "    storage_path=PROCESSED_DATA_GCS_PATH,\n",
        "    purpose=\"Processed Features for Training\",\n",
        "    recommended_class=\"STANDARD\", # Frequently accessed during training\n",
        "    lifecycle_policy_planned=True # Consider deleting old versions after model training\n",
        ")\n",
        "log_storage_best_practice(\n",
        "    storage_path=MODEL_ARTIFACTS_GCS_PATH,\n",
        "    purpose=\"Trained Model Artifacts and Checkpoints\",\n",
        "    recommended_class=\"STANDARD\", # Needs to be readily available for deployment\n",
        "    lifecycle_policy_planned=True # Implement retention policies for old model versions\n",
        ")\n",
        "\n",
        "\n",
        "# Scenario 3: Model Prediction Endpoint Configuration\n",
        "logging.info(\"\\n--- Configuring Prediction Endpoint (Cost-Awareness) ---\")\n",
        "# When deploying a Vertex AI Prediction Endpoint:\n",
        "PREDICTION_MACHINE_TYPE = \"n1-standard-2\" # Smaller instance for initial serving\n",
        "MIN_REPLICA_COUNT = 1\n",
        "MAX_REPLICA_COUNT = 5 # Allow scaling up to 5 instances\n",
        "\n",
        "log_compute_resource_params(\n",
        "    task_name=\"online_prediction_endpoint\",\n",
        "    machine_type=PREDICTION_MACHINE_TYPE,\n",
        "    accelerator_type=None, # Unless needed for inference\n",
        "    accelerator_count=0,\n",
        "    is_preemptible=False # Not for online serving!\n",
        ")\n",
        "logging.info(f\"Prediction endpoint configured with auto-scaling: Min {MIN_REPLICA_COUNT}, Max {MAX_REPLICA_COUNT}.\")\n",
        "\n",
        "# Scenario 4: Usage of Vision AI / Gemini APIs\n",
        "logging.info(\"\\n--- Usage of Gemini/Vision AI APIs (Cost-Awareness) ---\")\n",
        "# Example of batching for cost efficiency\n",
        "NUMBER_OF_IMAGES_TO_PROCESS = 1000\n",
        "BATCH_SIZE = 16 # Process 16 images per API call, if API supports it\n",
        "\n",
        "logging.info(f\"Planning to process {NUMBER_OF_IMAGES_TO_PROCESS} images with batch size {BATCH_SIZE}.\")\n",
        "logging.info(\"Batching API calls can reduce overhead and potentially cost for certain Vision AI / Gemini APIs.\")\n",
        "logging.info(\"Consider caching frequently requested API responses for common inputs.\")\n",
        "logging.info(\"Explore fine-tuning smaller models for specific tasks instead of calling large foundation models for every single inference.\")\n",
        "\n",
        "# --- End of Example ---\n",
        "print(\"\\n--- MLOps Cost Management Awareness Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How to Use and Interpret in Jupyter:\n",
        "\n",
        "- **Environment Variables:** The code uses os.getenv for GCP_PROJECT_ID and GCP_REGION. It's a good practice to set these as environment variables in your Jupyter/Colab environment or through configuration files, rather than hardcoding them.\n",
        "- **COMMON_GCP_LABELS:** This is a crucial concept. Always apply these labels to every GCP resource you create in your MLOps pipeline. This includes VMs, GCS buckets, BigQuery tables, Vertex AI Training Jobs, Endpoints, etc. You can then use the GCP Billing reports to filter costs by these labels, giving you detailed insights into where your money is going (e.g., \"how much did our customer-churn-prediction project spend this month?\", \"what was the cost of dev environment vs. prod?\").\n",
        "- **log_compute_resource_params:** This helper function highlights the importance of explicitly choosing and logging the compute resources for each ML task.\n",
        "    - **machine_type:** Picking the right VM type (e.g., n1-standard-8 vs. e2-standard-4).\n",
        "    - **accelerator_type / count:** Crucial for GPU/TPU costs.\n",
        "    - **is_preemptible:** Using preemptible VMs for batch jobs or non-critical training can save a lot. Your training code must be able to checkpoint and resume if using preemptible VMs.\n",
        "- **log_storage_best_practice:** Emphasizes smart storage choices.\n",
        "    - **recommended_storage_class:** Using COLDLINE or ARCHIVE for infrequently accessed raw data is a big cost saver.\n",
        "    - **lifecycle_policy_planned:** This reminds you to configure GCS bucket lifecycle management rules to automatically transition data to cheaper tiers or delete it after a certain period.\n",
        "\n",
        "- **Scenario 3: Model Prediction Endpoint:** Highlights auto-scaling for prediction endpoints, a key cost optimization strategy for variable inference loads.\n",
        "\n",
        "- **Scenario 4: Vision AI / Gemini APIs:** Points out higher-level optimization strategies for managed AI APIs (batching, caching, potentially fine-tuning smaller models).\n",
        "\n",
        "To truly manage costs, this code snippet is a starting point for awareness. You'd couple it with:\n",
        "\n",
        "- **Regular GCP Billing Reviews:** Use the Google Cloud Console's billing reports to drill down into costs, filter by labels, and identify anomalies.\n",
        "- **Budget Alerts:** Set up budget alerts in Cloud Billing to get notified when spending approaches your limits.\n",
        "- **Automated Cleanup Scripts:** Develop Cloud Functions or Cloud Run jobs that periodically check for and shut down idle resources (e.g., Vertex AI Workbench instances) or delete old, unneeded artifacts.\n",
        "- **Cost Optimization Tools:** Explore GCP's Cost Management recommendations directly in the console.\n",
        "\n",
        "Cost management in MLOps is an ongoing effort that requires continuous monitoring, optimization, and a cultural shift towards resource awareness within your ML teams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Organizational Alignment and Collaboration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Challenge of Organizational Alignment and Collaboration in MLOps\n",
        "\n",
        "MLOps requires a fundamental shift from traditional software development or even traditional data science. It's truly multidisciplinary, and this creates inherent friction points:\n",
        "\n",
        "- Siloed Teams and Conflicting Priorities:\n",
        "    - **Data Scientists:** Often focused on research, model performance, and new algorithms. May lack awareness or experience with production readiness, scalability, or operational concerns. Their incentive structure might reward model accuracy above all else.\n",
        "    - **ML Engineers:** Bridge the gap but might struggle with getting buy-in from data scientists on engineering best practices, or from IT/Ops on adopting new ML-specific infrastructure.\n",
        "    - **Data Engineers:** Focused on reliable data pipelines, data quality, and data governance, but might not fully understand the specific feature engineering needs or real-time data requirements of ML models.\n",
        "    - **Software/DevOps Engineers:** Experts in robust system development, CI/CD, and infrastructure, but may lack understanding of ML-specific nuances like model drift, data versioning, or the iterative nature of ML development. They might view ML models as just another piece of software, underestimating their unique operational challenges.\n",
        "    - **Business Stakeholders:** Focused on ROI, business impact, and quick delivery, potentially pushing for deployment before models are truly production-ready. May not understand the complexity or iterative nature of ML.\n",
        "\n",
        "- Lack of Shared Language and Understanding:\n",
        "    - Different teams use different jargon and have different mental models of the ML lifecycle. This leads to miscommunication, misunderstandings, and delayed decision-making.\n",
        "    - For example, what \"production-ready\" means can vary wildly between a data scientist (model works on test set) and a DevOps engineer (model is containerized, monitored, scalable, and resilient).\n",
        "\n",
        "- Ambiguous Roles and Responsibilities:\n",
        "    - Who owns the model once it's deployed? Is it the data scientist who built it, the ML engineer who deployed it, or the operations team?\n",
        "    - Who is responsible for model monitoring, retraining, and incident response when a model degrades?\n",
        "    - Without clear definitions, critical tasks can fall through the cracks, leading to unmanaged technical debt or production outages.\n",
        "\n",
        "- Ineffective Communication Channels and Feedback Loops:\n",
        "    - Slow or non-existent feedback loops between model performance in production and the data scientists responsible for model improvement.\n",
        "    - Lack of structured communication about data quality issues identified by production systems back to data engineering.\n",
        "    - \"Throwing models over the fence\" to operations without proper documentation or runbooks.\n",
        "\n",
        "- Resistance to Change and New Tools/Processes:\n",
        "    - Adopting MLOps often means changing established ways of working, introducing new tools, and requiring new skills. This can face resistance from individuals or teams comfortable with their existing methods.\n",
        "    - Data scientists might feel MLOps adds too much \"overhead\" to their creative work, while engineers might be wary of supporting \"unstable\" ML workloads.\n",
        "\n",
        "- Budget and Resource Allocation Challenges:\n",
        "    - MLOps requires investment in people, tools, and cloud infrastructure. Without clear organizational alignment on its value, securing adequate budget can be difficult.\n",
        "    - Competition for shared resources (e.g., GPU clusters, data engineering support)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategies for Fostering Organizational Alignment and Collaboration in MLOps\n",
        "\n",
        "- Define Clear Roles and Responsibilities (RACIs):\n",
        "    - **MLOps Lead/Manager:** Often critical to bridge the gaps between teams, define strategy, and ensure smooth execution.\n",
        "    - **Establish RACI Matrix:** For key MLOps activities (e.g., data preparation, feature engineering, model training, deployment, monitoring, incident response, retraining), clearly define who is Responsible, Accountable, Consulted, and Informed.\n",
        "    \n",
        "    - Example Ownership:\n",
        "        - **Data Scientist:** Model design, feature selection, experiment analysis, model performance improvement.\n",
        "        - **ML Engineer:** Productionizing features, building robust training/serving pipelines, model deployment, monitoring setup, incident response (Tier 1).\n",
        "        - **Data Engineer:** Data ingestion, core data quality, feature store management.\n",
        "        - **DevOps/Platform Engineer:** Cloud infrastructure provisioning, security, CI/CD platform, observability stack.\n",
        "        - **Business Owner:** Defines success metrics, validates model impact.\n",
        "\n",
        "- Foster a Shared Understanding and Language:\n",
        "    - **Common Vocabulary:** Create a glossary of MLOps terms and ensure everyone uses them consistently.\n",
        "    Cross-Training & Workshops: Organize regular sessions where different teams teach others about their domain (e.g., a DevOps engineer explaining CI/CD to data scientists, a data scientist explaining model evaluation metrics to operations).\n",
        "    - **\"MLOps 101\" for Everyone:** Provide foundational training for all relevant stakeholders, including business leaders, on the MLOps lifecycle and its complexities.\n",
        "    - **Joint Problem Solving:** Encourage mixed teams to work together on solving real-world production issues, building empathy and understanding.\n",
        "\n",
        "- Establish Clear Communication Channels and Feedback Loops:\n",
        "    - **Dedicated MLOps Slack/Teams Channels:** For real-time communication.\n",
        "    - **Regular Sync Meetings:** Short, focused meetings with representatives from all involved teams to discuss progress, blockers, and upcoming changes.\n",
        "    - **Automated Alerts & Dashboards:** Use Cloud Monitoring and Vertex AI Model Monitoring to automatically alert relevant teams when a model degrades or a data quality issue arises. Dashboards provide a shared source of truth on model health.\n",
        "    - **Post-Mortems for ML Incidents:** Conduct blameless post-mortems for production issues that involve ML models, focusing on systemic improvements and shared learning.\n",
        "\n",
        "- Implement Standardized Processes and Tools:\n",
        "    - **\"Golden Paths\":** Define clear, documented, and ideally automated \"golden paths\" for common MLOps workflows (e.g., \"this is how we deploy a new model,\" \"this is our standard model monitoring setup\").\n",
        "    - **Centralized Platform:** Leverage a unified MLOps platform (like Vertex AI) to provide a single pane of glass and common interfaces for data scientists and engineers. This reduces friction and tool proliferation.\n",
        "    - **Templates:** Provide pre-built templates for Vertex AI Pipelines, Dockerfiles, and model serving configurations.\n",
        "\n",
        "- Promote a Culture of Continuous Improvement and Shared Accountability:\n",
        "    - **\"You Build It, You Run It\" (with an ML Twist):** Encourage data scientists and ML engineers to be involved in the operational aspects of their models, fostering ownership beyond just model accuracy.\n",
        "    - **Shared Metrics:** Define success metrics that span across teams (e.g., \"time to model value,\" \"model uptime,\" \"drift detection rate\") rather than siloed metrics.\n",
        "    - **Celebrate MLOps Wins:** Highlight successful MLOps initiatives and the value they bring to the business.\n",
        "    - **Leadership Buy-in:** Crucial for success. Senior leadership must understand and champion MLOps as a strategic imperative, allocating necessary resources and enforcing cross-functional collaboration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conceptual Example: A Joint Retraining Protocol\n",
        "\n",
        "This isn't code, but a high-level description of a collaborative process that integrates different teams' responsibilities.\n",
        "\n",
        "**Scenario:** A deployed fraud detection model (powered by Vertex AI) is showing signs of concept drift detected by Vertex AI Model Monitoring.\n",
        "\n",
        "- Collaborative Protocol:\n",
        "\n",
        "    - Alert Trigger (Automated - Operations/ML Engineer):\n",
        "        - Vertex AI Model Monitoring detects significant drift in prediction distribution (or actual performance drop, if ground truth is available).\n",
        "        - An alert is triggered in Cloud Monitoring, sent to the ML Ops Slack channel and the on-call ML Engineer.\n",
        "\n",
        "    - Initial Triage & Diagnosis (ML Engineer / Data Scientist):\n",
        "        - **ML Engineer:** Investigates the alert. Checks Vertex AI Model Monitoring dashboards, Cloud Logging for recent prediction errors, and Cloud Monitoring for resource spikes. Pulls recent production data samples.\n",
        "        - **Data Scientist (Consulted):** ML Engineer brings initial findings to the data scientist. Together, they analyze the drifted data, potentially using Vertex Explainable AI to see if the model is behaving unexpectedly on new data patterns. They confirm it's likely concept drift, not a data pipeline bug.\n",
        "        - **Data Engineer (Consulted/Informed):** If there's suspicion of data quality issues or changes in upstream sources, the Data Engineer is consulted to verify data pipeline health.\n",
        "\n",
        "    - Retraining Decision & Prioritization (Business/Data Scientist/ML Engineer):\n",
        "        - Based on the severity of the drift and its business impact, the Business Stakeholder (e.g., Head of Fraud) is informed and a decision is made to retrain the model.\n",
        "        - Data Scientist proposes a retraining strategy (e.g., use the last 3 months of data, potentially re-evaluate features).\n",
        "\n",
        "    - Retraining Execution (ML Engineer / Data Scientist):\n",
        "        - **ML Engineer:** Triggers the Vertex AI Pipeline for automated retraining. This pipeline:\n",
        "            - Pulls fresh, labeled data from BigQuery (managed by Data Engineering).\n",
        "            - Performs feature engineering (reusing existing Vertex AI Feature Store or pipeline components).\n",
        "            - Trains the model (using Vertex AI Custom Training, potentially with new hyperparameters from Vertex AI Experiments).\n",
        "            - Evaluates the new model against a fresh validation set.\n",
        "            - Registers the new model version in Vertex AI Model Registry.\n",
        "        - **Data Scientist (Consulted/Informed):** Monitors the training run through Vertex AI Experiments, reviewing metrics and ensuring the new model performs as expected on test data.\n",
        "\n",
        "    - Deployment & A/B Testing (ML Engineer / DevOps Engineer):\n",
        "        - **ML Engineer:** Initiates a phased deployment using Vertex AI Prediction Endpoints (e.g., A/B testing the new model version against the old one, or a canary deployment).\n",
        "        - **DevOps Engineer (Consulted/Informed):** Ensures the deployment infrastructure is robust, monitors the new model's resource consumption and stability.\n",
        "\n",
        "    - Post-Deployment Monitoring & Evaluation (ML Engineer / Data Scientist / Business):\n",
        "        - **ML Engineer:** Continues monitoring the new model's performance in production via Vertex AI Model Monitoring.\n",
        "        - **Data Scientist:** Confirms that the concept drift has been mitigated and model performance is restored/improved based on delayed ground truth.\n",
        "        - **Business Stakeholder:** Validates the positive business impact of the retrained model.\n",
        "\n",
        "This structured approach, facilitated by GCP's MLOps suite, ensures that each team plays its part effectively, communication is streamlined, and the overall objective of maintaining high-performing ML models in production is met."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Ethical AI and Bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding Ethical AI and Bias\n",
        "\n",
        "Ethical AI refers to the development and deployment of AI systems in a way that respects human rights, promotes fairness, ensures transparency, and prioritizes safety and accountability. It's about designing AI to be beneficial to humanity and to minimize potential harms.\n",
        "\n",
        "AI Bias refers to systematic and repeatable errors in an AI system's output that create unfair outcomes, favoring some groups or individuals over others. These biases are often unintentional but can have significant negative consequences.\n",
        "\n",
        "- Common Sources of AI Bias:\n",
        "\n",
        "    - Data Bias (Most Common):\n",
        "        - **Historical Bias:** Data reflects past societal prejudices and inequalities (e.g., historical hiring data showing gender imbalance).\n",
        "        - **Selection Bias:** Data is not representative of the real-world population it's meant to serve (e.g., facial recognition trained mostly on light-skinned individuals).\n",
        "        -** Measurement Bias:** Inconsistent or inaccurate data collection (e.g., sensors performing differently across demographics).\n",
        "        - **Labeling Bias:** Human annotators introducing their own biases during data labeling (e.g., subjective classifications).\n",
        "        - **Underrepresentation/Overrepresentation:** Certain groups are not sufficiently or are excessively represented in the training data.\n",
        "\n",
        "    - Algorithmic Bias:\n",
        "        - **Optimization Bias:** The objective function or loss function used during training implicitly prioritizes certain outcomes or groups.\n",
        "        - **Algorithmic Design Bias:** Choices made in the algorithm's architecture or feature selection inadvertently create biased outcomes, even with unbiased data.\n",
        "\n",
        "    - Human/Cognitive Bias (Developer Bias):\n",
        "        - Assumptions and prejudices of the developers, data scientists, or MLOps engineers involved in designing, building, or evaluating the system.\n",
        "        - **Confirmation bias:** Seeking out information that confirms pre-existing beliefs during development.\n",
        "\n",
        "    - Systemic/Deployment Bias:\n",
        "        - How the AI system is integrated into real-world processes can introduce bias, even if the model itself seems fair (e.g., a fair risk assessment model used only on specific demographics for further scrutiny).\n",
        "        - **Feedback Loops:** Biased outputs from an AI system influencing future input data, creating a self-reinforcing cycle of bias.\n",
        "\n",
        "- Why it Matters (Impacts):\n",
        "    - **Discrimination:** In areas like hiring, lending, criminal justice, and healthcare.\n",
        "    - **Exacerbation of Inequality:** Widening the gap for marginalized communities.\n",
        "    - **Erosion of Trust:** Users lose faith in AI systems and the organizations deploying them.\n",
        "    - **Legal and Regulatory Risks:** Increasing scrutiny and emerging regulations (e.g., EU AI Act, various state laws) with significant penalties.\n",
        "    - **Reputational Damage:** Public outcry and negative press.\n",
        "    - **Unreliable Decisions:** Biased models lead to poor, unfair, or even dangerous outcomes.\n",
        "\n",
        "- Ethical AI Principles (Common Themes):\n",
        "\n",
        "Many frameworks (e.g., Google's AI Principles, OECD, IEEE, EU) share common themes:\n",
        "\n",
        "- **Fairness and Non-Discrimination:** AI systems should treat all individuals and groups equitably and avoid unfair outcomes.\n",
        "- **Accountability:** There should be clear responsibility for the design, development, deployment, and operation of AI systems, with mechanisms for oversight and redress.\n",
        "- **Transparency and Explainability:** AI systems should be understandable, allowing users and stakeholders to comprehend how decisions are made, especially in high-stakes applications.\n",
        "- **Privacy and Security:** Personal and sensitive data used by AI systems must be protected against misuse, breaches, and unauthorized access.\n",
        "- **Robustness and Reliability:** AI systems should operate consistently and safely, handling unexpected inputs or adversarial attacks gracefully.\n",
        "- **Human Agency and Oversight:** AI should augment, not replace, human decision-making, allowing for human intervention and control.\n",
        "- **Societal and Environmental Well-being:** AI should contribute positively to society and consider its broader impact.\n",
        "\n",
        "### Addressing Ethical AI and Bias in MLOps (with GCP context)\n",
        "\n",
        "This is a continuous, multi-stage process throughout the entire MLOps lifecycle.\n",
        "\n",
        "#### 1. Data Collection & Preparation:\n",
        "\n",
        "- **Diversity and Representation:** Actively collect diverse and representative datasets. Prioritize data from underrepresented groups.\n",
        "- **Bias Auditing:**\n",
        "    - **Statistical Analysis:** Analyze demographic distributions, feature correlations, and potential proxies for sensitive attributes.\n",
        "    - **Domain Expertise:** Involve subject matter experts and ethicists to identify potential biases.\n",
        "    - **Tools:** Use libraries like Fairlearn or TensorFlow Data Validation to identify imbalances or anomalies.\n",
        "- **Data Governance & Lineage:** Understand the source, history, and potential biases of your data using Vertex AI Metadata.\n",
        "- **Privacy-Preserving Techniques:**\n",
        "    - **Differential Privacy:** Add noise to data to protect individual privacy while allowing aggregate analysis.\n",
        "    - **Federated Learning:** Train models on decentralized data without centralizing raw personal data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Model Development & Training:\n",
        "\n",
        "- Fairness-Aware Algorithms:\n",
        "    - **Pre-processing Techniques:** Re-weighting data, resampling, or oversampling minority classes to balance representation before training.\n",
        "    - **In-processing Techniques:** Modify the training algorithm itself (e.g., adding fairness constraints to the loss function, adversarial debiasing like MinDiff in TensorFlow).\n",
        "    - **Post-processing Techniques:** Adjust model predictions after training to achieve desired fairness metrics (e.g., re-ranking, thresholding).\n",
        "- Robust Evaluation:\n",
        "    - **Disaggregated Metrics:** Evaluate model performance (accuracy, precision, recall, F1-score) across different subgroups (e.g., by gender, age, race).\n",
        "    - **Fairness Metrics:** Go beyond standard ML metrics to use fairness-specific metrics like:\n",
        "        - **Demographic Parity:** Equal positive prediction rates across groups.\n",
        "        - **Equalized Odds:** Equal true positive rates and false positive rates across groups.\n",
        "        - **Equality of Opportunity:** Equal true positive rates across groups.\n",
        "    - **Counterfactual Analysis:** Test how model predictions change if a sensitive attribute is altered while other features remain the same.\n",
        "- **Team Diversity:** Build diverse ML teams to bring different perspectives and help identify subtle biases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Model Deployment & Monitoring (Crucial MLOps Role):\n",
        "\n",
        "- **Vertex AI Model Monitoring:** Set up monitoring for:\n",
        "    - **Data Drift:** Detect changes in the distribution of incoming prediction requests compared to training data. This can indicate new, unrepresented demographics or contexts.\n",
        "    - **Concept Drift:** Detect changes in the relationship between input features and the target variable, which might signal a model becoming unfair over time.\n",
        "    - **Performance Degradation:** Monitor actual model performance (if ground truth is available) across different subgroups.\n",
        "- Explainable AI (XAI) - Vertex Explainable AI:\n",
        "    - **Feature Attributions:** Understand which features contribute most to a model's prediction for individual instances or globally. This can reveal if a model is relying too heavily on biased features.\n",
        "    - **Visualizations:** Use tools to visualize model behavior and identify unexpected patterns.\n",
        "    - **For Gemini/LLMs:** Prompt engineering techniques to elicit explanations from the model, and tools to inspect attention mechanisms.\n",
        "- **Human-in-the-Loop:** Implement human oversight, review, and override mechanisms for high-stakes decisions made by AI.\n",
        "- **A/B Testing/Canary Deployments:** Carefully test new model versions in production, monitoring fairness metrics alongside performance before full rollout.\n",
        "- **Rollback Capabilities:** Be prepared to quickly roll back to previous, less biased model versions if issues are detected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Governance & Accountability:\n",
        "\n",
        "- **Ethical AI Principles:** Formalize your organization's ethical AI principles and integrate them into the MLOps lifecycle.\n",
        "- **Impact Assessments:** Conduct AI ethics impact assessments for new high-risk AI systems before deployment.\n",
        "- **Model Cards/Documentation:** Document models thoroughly, including:\n",
        "    - Intended use cases and limitations.\n",
        "    - Training data sources and characteristics.\n",
        "    - Performance metrics (including fairness metrics across subgroups).\n",
        "    - Known biases and mitigation strategies applied.\n",
        "    - Responsible use guidelines.\n",
        "    \n",
        "    (GCP's Model Registry in Vertex AI can store much of this metadata).\n",
        "\n",
        "- **Auditing and Traceability:** Maintain clear audit trails for data, code, model versions, and deployment decisions using Vertex AI Metadata.\n",
        "- **Legal & Compliance Teams:** Involve legal and compliance teams early and often to navigate emerging regulations and ensure adherence to ethical guidelines.\n",
        "- **Red Teaming (for Gen AI/LLMs):** Actively probe generative AI models (like Gemini) with harmful prompts to identify vulnerabilities related to bias, toxicity, hallucination, etc., before deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GCP Vertex AI's Responsible AI Toolkit\n",
        "\n",
        "Google Cloud has integrated Responsible AI tools directly into Vertex AI to help with this:\n",
        "\n",
        "- **Vertex AI Model Monitoring:** For data and concept drift, performance monitoring.\n",
        "- **Vertex Explainable AI:** Provides feature attributions (integrated with various model types).\n",
        "- **Vertex AI Pipelines and Metadata:** For end-to-end lineage tracking, reproducibility, and auditing.\n",
        "- **Vertex AI Feature Store:** Helps manage consistent, curated features to reduce bias from inconsistent feature engineering.\n",
        "- Generative AI on Vertex AI (including Gemini):\n",
        "    - **Safety Filters:** Built-in content filtering for generated text/images to block harmful or biased outputs.\n",
        "    - **Safety Attribute Scoring:** Provides scores for different harm categories (e.g., toxicity, hate speech, sexual content) to help developers understand and manage model outputs.\n",
        "    - **Prompt Engineering Guidance:** Best practices to design prompts that lead to less biased and safer outputs.\n",
        "    - **Responsible Generative AI Toolkit:** Offers guidance and tools for responsible application design, safety alignment, and model evaluation (e.g., LLM Comparator for side-by-side evaluation).\n",
        "\n",
        "Ethical AI and bias mitigation are not one-time tasks; they are continuous processes that require diligence, interdisciplinary collaboration, and a commitment from the entire organization throughout the MLOps lifecycle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_batch_prediction.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
