{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Versioning**\n",
        "\n",
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Keeyana Jones](https://github.com/keeyanajones/) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Overview**\n",
        "\n",
        "Data versioning, much like version control in software development (e.g. Git), is the practice of tracking and managing changes to datasets over time.  It involves creating a historical record of all modifications, additions, and deletions made to data, allowing users to revert to previous states, compare different versions, and understand the evolution of the data.\n",
        "\n",
        "While similar in concept to code versioning, data bersioning presents unique challenges due to the potentially massive size and dynamic nature of datasets.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Why is Data Versioning Crucial?**\n",
        "\n",
        "In todays data driven world, data versioning is no longer a luxury but a necessity, especially for data intensive fields like dat science, machine learning (ML), and analytics.  Here's why:\n",
        "1. **Reproducibility**\n",
        "   - **Scientific Rigor:** For research, experiments, and analyses, being able to precisely replicate results is fundamental. Data versioning ensures you know exactly which version of the data was used to train a specific model or generate a particular report.\n",
        "   - **Debugging:** if a models performance suddenly degrades, or an analytical report shows inconsistencies, versioning allows you to pinpoint when and where the data might have changed, making debugging much more efficient. \n",
        "2. **Collaboration**\n",
        "   - In team environments, multiple data scientists, analysts, or engineers may be working on the same datasets simultaneously.  Versioning prevents conflicts, accidental overwrites, and ensures everyone is working with the correct and consistent data. \n",
        "   - It enable branching, merging, and reviewing changes to data similar to how code is managed in Git.\n",
        "3. **Auditability and Compliance**\n",
        "   - for industries with strict regulations (e.g., finance, healthcare, legal), an immutable audit trail of data modification is essential for compliance (e.g., GDPR, HIPAA).  Data versioning provides a transparent history of who changed what, when, and why.\n",
        "   - it helps demonstrate data lineage, showing how data was transformed from its raw state to its final form.\n",
        "4. **Experimentation and Iteration**\n",
        "   - Data science and ML ae iterative processes.  Data versioning allows data scientist to experiment freely with different data preprocessing steps, feature engineering techniques, or even entirely different datasets without fear of losing previous work or corrupting the main dataset.\n",
        "   - You can easily compare the impact of different data versions on model performance.\n",
        "5. **Data Integrity and Reliability**\n",
        "   - Data is rarely static; its constantly updated, corrected, or appended.  Versioning helps maintain the integrity and consistency of your data over time.\n",
        "   - If a data corruption or error is introduced, you can quickly roll back to a stable, previous version.\n",
        "6. **Model and Code Linkage (MLOPs):**\n",
        "   - In machine learning, the performance of a model is inherently tired to the code that trained it AND the data it was train on.  Data versioning, whe integrated with code versioning, provides a complete snapshot of an ML experiment, crucial for MLOps.  \n",
        "   - This ensures that models can be retained on the exact data they were originally trained on, or on specific updated versions.     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **How Data Versioning is Implemented:**\n",
        "\n",
        "Implementing data versioning can range from simple practices to sophisticated systems:\n",
        "1. **Simple Approaches (Manual/File-Based):**\n",
        "   - **Versioning by Name/Date:**\n",
        "   Appending version numbers (e.g., `data_v1.csv`, `data_v2.csv`) or time stamps (`data_20250614.csv`) to filenames.\n",
        "   - **Directory Based Versions:** Storing different versions of a dataset in separate directories (e.g., `/datasets/v1/`, `/datasets/v2/`).\n",
        "   - **Limitations:** Inefficient for large datasets (full duplication), prone to human error, difficult to track granular changes or merge.   \n",
        "2. **Database Versioning (temporal Tables/Slowly Changing Dimensions - SCD Type 2):**\n",
        "   - Relational databases often support concepts like \"temporal tables\" or \"valid from/to\" column (SCD Type 2) to track changes to individual records over time.  When a record is updated, a new record is inserted with the new value and an updated validity period, while the old records validity period is closed.\n",
        "   - **Limitations:** Primarily for structured, row level changes; not ideal for large, unstructured files or entire datasets.       \n",
        "3. **Dedicated Data Version Control Systems (DVCS)/Data Lake Versioning**   \n",
        "   - These tools are designed specifically to handle the unique challenges of versioning large and diverse datasets, often by adapting Git like concepts to data storage. They often work by storing metadata about data versions in a GIT repository, while the actual large data files are stored separately (e.g., in cloud storage or a data lake).\n",
        "   - **Key Features**\n",
        "      - **Deduplication/Efficient Storage:** Instead of ull copies, they often store deltas (changes) or use content addressable storage to avoid duplicating unchanged data blocks.\n",
        "      - **Git like Workflow:** Support for branching, merging, committing, and tagging data versions.\n",
        "      - **Data Lineage:** Tracking the transformations applied to data over different versions.\n",
        "      - **Integration with ML Frameworks:** Often designed to integrate with machine learning pipelines and MLOps tools.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Popular Data Versioning Tools and Concepts**\n",
        "\n",
        "- **DVC (Data Version Control):** An Open-source tool that works with Git.  It tracks metadata about large file (data, models) in Git, while the actual data is stored externally (e.g., S3, Google Cloud Storage, local storage).  It lets you create snapshots of data, restore versions, and reproduce experiments.  \n",
        "- **lakeFS:** a version layer for data lakes build on Git like semantics.  It enables branching, merging, and reverting on massive datasets stored in S3 or other object storage.  \n",
        "- **Pachyderm:** A platform that builds data versioning directly into its data driven pipelines, providing immutable data lineage and automating the versioning process data flows through transformations.\n",
        "- **Doit:** a SQL database with git like versioning features.  You can clone, branch, merge, diff, and push/pull database changes.\n",
        "- **Apache Iceberg/Delta Lake/Apache Hudi:** These are open table formats for data likes that provide transaction support, schema evaluation, and time travel capabilities, which implicitly offer data versioning by allowing users to query previous states of tables.\n",
        "- **Git LFS (Large File Storage):** An extension for Git that allows versioning of large files by storing versioning of large files by storing pointers in Git and the Actual files in a separate large file store. Useful for smaller scale data versioning alongside code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Best Practices for Data Versioning**\n",
        "\n",
        "- **Define a Versioning Strategy:** Decide when to create new versions (e.g., after major data updates, schema changes, or before model training).\n",
        "- **Automate versioning:** integrate versioning into your data pipelines and workflows to reduce manual errors and ensure consistency.\n",
        "- **Document changes:** Always include clear metadata, change logs, and descriptions for each data version.  Why was the change made? What does this version represent?\n",
        "- **Link Data Versions to code and Models:** for ML projects, ensure you can trace back which specific data version was used with which specific code version to produce a particular model.  \n",
        "- **Choose the right tool:**  Select a data versioning tool that fits your data volume, team, size, existing infrastructure, and specific use cases.  \n",
        "- **Consider Storage Efficiency:** For large datasets, prefer tools that use incremental storage or deduplication over full data duplication. \n",
        "- **Implement Data Governance:** Establish clear policies and responsibilities for managing data versions within your organization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By embracing data versioning, organizations can achieve greater reliability, transparency, and efficiency in their data driven initiatives, ultimately leading to more robust and trustworthy ai systems and analytical insights. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_batch_prediction.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
