{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Local Docker Testing**\n",
        "\n",
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Keeyana Jones](https://github.com/keeyanajones/) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Overview**\n",
        "\n",
        "Local Docker testing refers to the practice of building, running, and testing your application (or parts of it, like a microservice or an ML model) within Docker containers on your local development machine.  Its a fundamental part of a modern development workflow, especially in the context of microservices, cloud native applications, and MLOps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Why is Local Docker Testing Important?**\n",
        "\n",
        "1. Environment Consistency (Reproducibility):\n",
        "   - **It works on my machine! Problem:** This is the primary problem Docker solves.  Docker containers package your application and all its dependencies into a single isolated unit.  Testing locally in Docker ensures that the environment your application runs in during development is identical to the production environment, reducing surprises during deployment.\n",
        "   - **Eliminates Dependency Conflicts:** You don't have to worry about conflicting versions of libraries or runtimes installed on your host machine.  \n",
        "\n",
        "2. Isolation:\n",
        "   - Each container runs in its own isolated environment, preventing conflicts between different projects or services running on your machine. \n",
        "   - You can easily spin up and tear down multiple instances of your application or its dependencies (e.g., a database, a message queue) without cluttering your host system.\n",
        "   \n",
        "3. Faster Development Cycles:\n",
        "   - **Quick Spin-up/Tear-down:** Containers start much faster than virtual machines, allowing for rapid iteration and testing.\n",
        "   - **Simplified Dependency Management:** No need to manually install and configure complex services like databases; just define them in `docker-compose.yml`.\n",
        "\n",
        "4. Simulating Production:\n",
        "   - You can test how your application interacts with other services (databases, message queues, other microservices) by running them all as containers using tools like Docker Compose.  This closely mimics a production deployment.\n",
        "   - Enables testing of networking, port mappings, and volume mounts before deploying to a more complex environment like Kubernetes.\n",
        "   \n",
        "5. Collaboration:\n",
        "   - Developers on a team can share a `Dockerfile` and `docker-compose.yml` to ensure everyone is working with the same setup, leading to smother handoffs and fewer works on my machine issues.\n",
        "   \n",
        "6. CI/CD Alignment:\n",
        "   - if your CI/CD pipeline uses Docker to build and test, local Docker testing helps catch issues earlier in the development cycle, reducing the feedback loop and ensuring successful CI/CD runs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **How to Perform Local Docker Testing:**\n",
        "\n",
        "The process typically involves the following steps:\n",
        "\n",
        "1. Create a Docker file:\n",
        "   - Define the environment and steps to build your applications image.  This includes specifying a base image, copying code, installing dependencies, exposing ports, and defining the command to run your application.  (See previous explanation on Dockerfile creation).\n",
        "\n",
        "2. Build the Docker image:\n",
        "   - Use the `docker build` command to create an immutable image from your Dockerfile.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "docker build -t my-app:latest ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Run the Docker Container:\n",
        "   - Use the `docker run` command to create and start a container from you built image. You can map ports, mount volumes, set environment variables, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "docker run -p 8000:8000 --name my-app-container my-app:latest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- You can then access your application (e.g., a web service) via `http://localhost:8000`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Use Docker Compose (for multiservice applications):\n",
        "   - For applications composed of multiple services (e.g., a web app, a database, a redis cache).  Docker Compose is invaluable.  You define all services, their dependencies, and networking in a `docker-compose.yml` file.\n",
        "   - `docker-compose.yml` example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "version: '3.8'\n",
        "services:\n",
        "   web:\n",
        "      build: .\n",
        "      ports: \n",
        "         - \"8000:8000\"\n",
        "      environment:\n",
        "         DATABASE_URL: postgres://user:password@db:5432/mydb\n",
        "      depends_on:\n",
        "         - db\n",
        "   db:\n",
        "      image: postgres:13\n",
        "      environment:\n",
        "        POSTGRES_DB: mydb\n",
        "        POSTGRES_USER: user\n",
        "        POSTGRES_PASSWORD: password\n",
        "      volumes:\n",
        "         - db_data:/var/lib/postgresql/data\n",
        "   volumes:\n",
        "      db_data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "docker-compose up -d # Build (if necessary) and start all services in detached mode\n",
        "docker-compose logs  # View logs from all services \n",
        "docker-compose down  # Stop and remove all services and networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Write and Run Tests:\n",
        "   - **Unit Test:** Run unit tests inside the container during the build process (as a `RUN` instruction in the Dockerfile, often in a multi stage build) or by executing `docker exec` commands on a running container.\n",
        "   - **Integration Test:** With Docker compose, you can spin up all dependent services and then run integration tests against your applications endpoint, ensuring inter service communication works as expected.\n",
        "   - **End to End Tests:** Use tools like Selenium (for APIs) to interact with your containerized application as an end user would.\n",
        "\n",
        "6. Debugging:\n",
        "   - **Attaching to Containers:** Most IDEs and debuggers can attach to processes running inside a Docker container.   \n",
        "   - **Logs:** `docker logs <container_name>` is essential for initial debugging. \n",
        "   - **Interactive Shell:** `docker exec -it <container_name> /bin/bash` (or `sh`) to get a shell inside the running container for inspection.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Best Practices for Local Docker Testing:**\n",
        "\n",
        "   - **Small, Focused Images:** Keep your Dockerfiles lean to make builds faster and images smaller.  Use multi-stage builds to separate build dependencies from runtime dependencies.\n",
        "   - **Leverage Build Cache:** Order your Dockerfile instructions form least to most frequently changing to maximize cache hits during `docker build`. \n",
        "   - **Use `.dockerignore`:** Exclude unnecessary files (e.g., `.git`, `node_modules`, `__pycache__`, `venv`) from the build context to speed up builds and reduce image size. \n",
        "   - **Environment Variables:** Use environment variables for configuration (e.g., database URLs, API keys) instead of hardcoding them in the Dockerfile.\n",
        "   - **Health Checks:** Define `HEALTHCHECK` instructions in your Dockerfile or Docker Compose to ensure containers are actually ready to serve requests before traffic is directed to them.\n",
        "   - **Volume Mounting for Development:** For rapid iteration on code changes, mount your local source code directory into the container using a Docker volume (`-v /path/to/local/code:/app`). This allows you to modify code on you host and see changes reflected in the container without rebuilding the image every time (requires live reloading in your application).\n",
        "   - **Container Naming:** Use meaningful names for your containers (`--name`) to easily identify and manage them.\n",
        "   - **Clean Up:** Regularly remove stopped containers (`docker rm`) and unused images (`docker rmi`) to free up disk space.  Use `docker system prune` for a comprehensive cleanup.\n",
        "   - **Adopt Docker Compose Early:** Even for single service apps, if you anticipate adding a database or another service, starting with Docker Compose can simplify future expansion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By consistently using Docker for local development and testing, you significantly streamline your workflow, improve collaboration, and build more reliable applications that seamlessly transition from your laptop to production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_batch_prediction.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
