{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Custom Training Logic**\n",
        "\n",
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Keeyana Jones](https://github.com/keeyanajones/) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Overview**\n",
        "\n",
        "Custom Training Logic often referred to as a custom training loop, is a fundamental concept in machine learning and deep learning, especially when you need more control and flexibility over the model training process than what pre-built, high level APIs (like Keras's `model.fit()`) offer.\n",
        "\n",
        "Here is a breakdown of what it means and why its used:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **What is Custom Training Logic?**\n",
        "\n",
        "At is core, a custom training loop involves writing the entire training process from scratch, step by step.  Instead of calling a single `fit()` method, you explicitly define:\n",
        "\n",
        "1. **Iteration over Epochs:** The number of times you want to iterate through your entire dataset.\n",
        "\n",
        "2. **Iteration over Batches:** Within each epoch, how you'll process your data in smaller chunks (batches). \n",
        "\n",
        "3. **Forward Pass:** How the input data is fed through your model to generate predictions.  \n",
        "\n",
        "4. **Loss Calculation:** How the model's predictions are compared to the actual target values to quantify the error (loss).\n",
        "\n",
        "5. **Backward Pass (Gradient Calculation):** How the gradients of the loss with respect to the models trainable parameters (weights and biases) are computed.  This is typically done using automatic differentiation libraries (like `torch.autograd` in PyTorch or `tf.GradientTape` in TensorFlow).\n",
        "\n",
        "6. **Optimizer Step:** How the models parameters are updated using an optimization algorithm (e.g., Stochastic Gradient Descent (SGD), Adam, RMSprop) and the calculated gradients.\n",
        "\n",
        "7. **Metrics Calculation and Logging:** How you track and report performance metrics (e.g., accuracy, precision, recall, F1-score) during training.\n",
        "\n",
        "8. **Validation/Evaluation:** Periodically evaluating the model's performance on a separate validation dataset to monitor for overfitting and track generalization.  \n",
        "\n",
        "9. **Checkpointing:** Saving the model's state (weights, optimizer state) at regular intervals or when performance improves, so you can resume training later or load the best model.  \n",
        "\n",
        "10. **Learning Rate Scheduling (Optional):** Dynamically adjusting the learning rate during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Why Use Custom Training Logic?**\n",
        "\n",
        "While high level APs are excellent for rapid prototyping and standard tasks, custom training logic becomes necessary or highly beneficial for several reasons:\n",
        "\n",
        "1. **Non-Standard Training Procedures** \n",
        "   - **Generative Adversarial Networks (GANs):**  GANs involve training two networks (generator and discriminator) in an adversarial manner.  This requires a specific, interleaved training loop that high level `fit()` methods don't natively support.\n",
        "   - **Reinforcement Learning:** Training agents in RL often involves complex interactions with environments, value functions, and policy updates that go beyond simple supervised learning loops.  \n",
        "   - **Meta-Learning:** Training models to learn to learn requires nested optimization loops.\n",
        "   - **Multi-task Learning:** When a single model is trained to perform multiple tasks simultaneously, with potentially different loss functions or optimization schemes for each task.  \n",
        "\n",
        "2. **Advanced Optimization Techniques**    \n",
        "   - Implementing custom learning rate schedules that are not build tinto standard optimizers (e.g., cyclical learning rates, warm up schedules).\n",
        "   - Applying custom regularization techniques directly in the loss computation or gradient updates. \n",
        "   - Developing novel optimization algorithms.\n",
        "\n",
        "3. **Complex Loss Functions**\n",
        "   - When loss functions is highly custom, involves multiple components, or requires specific intermediate computations that are not easily expressed within standard `compile()` or `add_loss()` methods. \n",
        "\n",
        "4. **Debugging and Granular Control** \n",
        "   - For researchers and advanced practitioners, a custom loop offers unparalleled visibility into the training process. You can inspect gradients, activations, and losses at any point, making debugging complex models much easier.\n",
        "   - It allows you to control every single step, which is invaluable for fine turning performance or implementing experimental ideas.  \n",
        "\n",
        "5. **Resource Management and Distributed Training** \n",
        "   - When training on multiple GPUs, TPUs, or across a cluster of machines, you often need to explicitly manage data distribution, gradient aggregation, and synchronization, which is more easily done with a custom loop.\n",
        "\n",
        "6. **Integration with custom Data Pipelines**\n",
        "   - if your data loading and preprocessing pipeline is highly specialized and doesn't fit neatly into standard `dataLoader` or `if.data.Dataset` patterns, a custom loop provides the flexibility to integrate it seamlessly.\n",
        "\n",
        "7. **Research and Experimentation**\n",
        "   - for cutting edge research, new model architectures, and novel training methodologies, pre-built abstractions often fall short.  Custom training logic is the bread and butter of ML research. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### EXAMPLE (CONCEPTUAL) Custom Training Loop\n",
        "\n",
        "# Model \n",
        "# Optimizer\n",
        "# Loss_fit\n",
        "# Train_Dataloader\n",
        "# Val_Dataloader\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training Phase \n",
        "    model_train()\n",
        "    total_train_loss = 0\n",
        "    correct_train_predictions = 0\n",
        "    total_train_samples = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_dataloader):\n",
        "        # 1. forward pass\n",
        "        predictions = model(inputs) \n",
        "        # 2. calculate loss\n",
        "        loss = loss_fn(predictions, targets)\n",
        "        # 3. Zero gradients (clear previous gradients)  \n",
        "        optimizer.zero_grand()\n",
        "        # 4. Backward pass (compute gradients)\n",
        "        loss.backward()\n",
        "        # 5. Optimizer step (update model parameters)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        predicted = torch.max(predictions.data, 1) \n",
        "        total_train_samples += targets.size(0)\n",
        "        correct_train_predictions += (predicted == targets).sum().item()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)           \n",
        "    train_accuracy = correct_train_predictions / total_train_samples\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss: .4f}, Train Act: {train_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# Validation Phase\n",
        "model_eval()\n",
        "total_val_loss = 0\n",
        "correct_val_predictions = 0\n",
        "total_val_samples = 0 \n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(val_dataloader):\n",
        "        predictions = model(inputs)\n",
        "        loss = loss_fn(predictions, targets)\n",
        "        total_val_loss += loss.item()\n",
        "        predicted = torch.max(predictions.data, 1)\n",
        "        total_val_samples += targets.size(0)\n",
        "        correct_val_predictions += (predicted == targets).sum().item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_dataloader)           \n",
        "    val_accuracy = correct_val_predictions / total_val_samples\n",
        "    print(f\"Epoch {epoch+1}, Val Loss: {avg_val_loss: .4f}, Val Act: {val_accuracy:.4f}\\n\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Frameworks provide convenient abstractions, understanding and implementing custom training logic is essential for deep learning practitioners who need maximum control, flexibility and the ability to innovate beyond standard training paradigms. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_batch_prediction.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
