{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Tensorboard**\n",
        "\n",
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Keeyana Jones](https://github.com/keeyanajones/) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Overview**\n",
        "\n",
        "TensorBoard is an open source visualization toolkit provided by the TensorFlow team (now integrated with Keras, PyTorch, and other ML frameworks) that helps you understand debug, and optimize your machine learning models.  It essentially takes the logs generated during you model training process and presents them in an interactive web based dashboard.\n",
        "\n",
        "Training complex machine learning models, especially deep neural networks, can be a black box with out proper tools.  TensorBoard shines by providing a window into this black box, allowing you to monitor progress, compare experiments, and diagnose issues. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Scalars:\n",
        "- **Purpose:** Visualize how scalar values (single numerical values) change over time (e.g., across epochs or training steps).\n",
        "- **Use Cases:** \n",
        "   - Tracking loss (training loss, validation loss) to see if the model is learning and generalizing.\n",
        "   - Monitoring metrics like accuracy, precision, recall, f1 score, RMSE, etc.\n",
        "   - Observing the learning rate schedule to ensure its decaying as expected\n",
        "   - Tracking training speed or throughput.\n",
        "- **Benefit:** Quickly identify overfitting (training loss decreases, validation loss increased), underfitting, or issues with learning rate.\n",
        "\n",
        "2. Graphs:\n",
        "- **Purpose:** Visualize how the computational graph of your model, representing the flow of data and operations.\n",
        "- **Use Cases:** \n",
        "   - Understanding the architecture of your neural network, including layers, connections, and operations.\n",
        "   - Debugging data flow issues or identifying unintended connections.\n",
        "   - Ensuring the model graph matches your intended design.\n",
        "   - Identifying potential bottlenecks or inefficient operations.\n",
        "- **Benefit:** Provides a high level and detailed view of your models structure, which is crucial for complex architectures.\n",
        "\n",
        "3. Histograms and Distributions:\n",
        "- **Purpose:** Show the distribution of tensors (like weights, biases, activations, or gradients) as they change over training steps/epochs.\n",
        "- **Use Cases:** \n",
        "   - Monitoring the distribution of model weights and biases to detect issues like vanishing or exploding gradients.\n",
        "   - Observing activation distributions to ensure values are within a reasonable range (e.g., not all zeros or saturated).\n",
        "   - Tracking gradient distributions to ensure they are stable and not too small or large.\n",
        "- **Benefit:** Crucial for debugging training instability and understanding how model parameters evolve.\n",
        "\n",
        "4. Images: \n",
        "- **Purpose:** Display images passed through the model or generated by the model.\n",
        "- **Use Cases:** \n",
        "   - Visualizing input images during preprocessing or augmentation.\n",
        "   - Monitoring generated images in generative models (GANs, VAEs)\n",
        "   - Displaying activation maps or feature visualizations to understand what the model is seeing.\n",
        "- **Benefit:** Essential for tasks involving computer vision to visually inspect the models performance and internal representations.\n",
        "\n",
        "5. Projector (for Embeddings):\n",
        "- **Purpose:** Visualize high dimensional data (like word embeddings, image embeddings, or latent space representations) by projecting them into lower dimensional space (2d or 3d) using techniques like t-SNE or PCA.\n",
        "- **Use Cases:** \n",
        "   - Exploring relationships between similar or dissimilar items in the embedding space.\n",
        "   - Debugging embedding quality (e.g., are similar words clustered together)\n",
        "- **Benefit:** Provides interactive exploration of complex data representations.\n",
        "\n",
        "6. HParam (HyperParameter Tuning):\n",
        "- **Purpose:** Compare the results of multiple training runs with different hyperparameter configurations.\n",
        "- **Use Cases:** \n",
        "   - Systematically evaluate how learning rate, batch size, optimizer choice, regularization, etc, impact model performance.\n",
        "   - identify the optimal combination of hyperparameters for your model.\n",
        "- **Benefit:** Streamlines the hyperparameter tuning process, helping to find the best model configuration.\n",
        "\n",
        "7. Text:\n",
        "- **Purpose:** Display text data, such as generated text, attention weights over text, or descriptions.\n",
        "- **Use Cases:** \n",
        "   - Monitoring outputs of NLP models.\n",
        "   - Visualizing text embeddings.\n",
        "\n",
        "8. Audio (less common for most ML, but useful for speech): \n",
        "- **Purpose:** Play audio files.\n",
        "- **Use Cases:** \n",
        "   - Monitoring outputs of speech synthesis models.\n",
        "   - Inspecting audio features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **How to Use TensorBoard:**\n",
        "\n",
        "The General workflow involves\n",
        "\n",
        "1. **Logging Data:** During your model training (or even data preprocessing/evaluation), you use logging APIs provided by your ML framework (e.g., `tf.summary` in TensorFlow/Keras, `torch.utils.tensorboard.SummaryWriter` in PyTorch, or integrations in libraries like Keras Callbacks). This writes data to event files in a specified \"log directory.\"\n",
        "2. **Launching TensorBoard:** After (or even during) training, you open your terminal and navigate to the directory containing your log files.  Then, you run the command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "tensorboard --logdir <your_log_directory>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This will start a local server (usually on `http://localhost:6006`) that serves the TensorBoard interface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. **Viewing the Dashboard:** Open your web browser and navigate to the URL provided by the command.  You'll see the TensorBoard dashboard, where you can explore your visualizations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Best Practices for Using TensorBoard:**\n",
        "\n",
        "- **Organize Log Directories:** Use a clear directory structure for your logs, often including timestamps or experiment names to differentiate runs (e.g., `logs/fit/20250617-1020_experiment_v1_1r001`). This is crucial for comparing experiments.\n",
        "- **Log Meaningful Metrics:** Don't just log everything. Focus on metrics that are important for evaluating your model and understanding its behavior.\n",
        "- **Use Callbacks (Keras):** If using Keras, the `tf.keras.callbacks.TensorBoard` callback simplifies logging a lot of common metrics, graphs, and histograms automatically.\n",
        "- **Balance Logging Frequency:** Log frequently enough to capture trends, but not so often that it creates massive log file s or slows down training significantly.  \n",
        "- **Name Your Runs:** Give descriptive names to your training runs so you can easily identify and compare them in TensorBoard.\n",
        "- **Use `tf.summary` (TensorFlow) or `SummaryWriter` (PyTorch) explicitly:** For custom logging (e.g., visualizing specific intermediate tensors, custom metrics), use the direct logging APIs.\n",
        "- **Consider Remote Access:** For models trained on cloud VMs or remote servers, you'll need to set up SSH tunneling or use cloud specific integrations (like Vertex AI Workbench's TensorBoard integration) to access the TensorBoard UI locally.\n",
        "- **Integrate with Experiment Tracking Platform:** For more advanced MLOps, TensorBoard often integrates with broader experiment tracking platforms like MLflow, Weights & Biases, or Neptune.ai, which can manage the logging and hosting of TensorBoard instances for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TensorBoard is an indispensable tool for anyone working with machine learning models, particularly in deep learning, as it transforms abstract numerical data into intuitive visualizations that greatly aid in model understanding, debugging, and performance optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_batch_prediction.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
