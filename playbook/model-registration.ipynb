{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Model Registration**\n",
        "\n",
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Keeyana Jones](https://github.com/keeyanajones/) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Overview**\n",
        "\n",
        "Model registration is a crucial component of the MLOps (Machine Learning Operations) lifecycle.  Its the process of centrally storing, versioning, and managing trained machine learning models, along with their associated metadata and artifacts, in a dedicated repository or model registry. \n",
        "\n",
        "Think of it as a library or catalog for all your trained models, making the discoverable, trackable, and ready for deployment or further use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Why is Model Registration Important?**\n",
        "\n",
        "Without a robust model registration process, managing ML models becomes chaotic, especially in team environments or as the number of models grows, it addresses several critical challenges:\n",
        "\n",
        "1. Centralized Management & Discoverability:\n",
        "   - **Problem:** Models are often scattered across different folders, cloud storage buckets, or personal machines, making it hard to find the right model.\n",
        "   - **Solution:** Provides a single, centralized location where all trained models are stored, making them easily discoverable by other data scientist, ML engineers, and applications.\n",
        "\n",
        "2. Versioning & Reproducibility:\n",
        "   - **Problem:** Its hard to know which model version was used for a specific deployment or if a particular experiment produced a certain model. Without proper versioning, reproducing results or debugging issues becomes a nightmare. \n",
        "   - **Solution:** Each registered model gets a unique version ID.  You can track changes, revert to previous versions, and ensure that specific model versions can be reliably reproduced. This often links back to experiment tracking data (parameters, metrics, code version, data version). \n",
        "\n",
        "3. Governance & Auditability: \n",
        "   - **Problem:** Lack of transparency about who trained a model, on what data, and how ti performs.  This is a major concern for compliance and regulated industries.\n",
        "   - **Solution:** Provides an audit trail: who registered the model, when, with what description, and often links to the training run, associated metrics, and even model cards for detailed documentation.  \n",
        "\n",
        "4. Deployment & Operationalization:\n",
        "   - **Problem:** Deploying models directly from training environments is risky and inconsistent.\n",
        "   - **Solution:** Model registration acts as a hand off point form experimentation to production. A registered model is considered  production ready or at least deployable. It standardizes how models are accessed for deployment (e.g., via a specific ID or alias).\n",
        "\n",
        "5. Collaboration: \n",
        "   - **Problem:** Data scientists in a team might duplicate work or struggle to share and validate each others models.\n",
        "   - **Solution:** Enables seamless collaboration, allowing team members to browse, understand, and use models registered by others.\n",
        "\n",
        "6. Lifecycle Management:\n",
        "   - **Problem:** Managing models through different stages (development, staging, production, archived) is complex.\n",
        "   - **Solution:** Supports lifecycle stages, allowing models to be promoted or demoted based on performance, testing, or approval workflows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **What Information is Stored in a model Registry?**\n",
        "\n",
        "A typical model registration entity includes:\n",
        "\n",
        "1. Model Artifacts:\n",
        "   - The actual saved model files (e.g., `.pk1` for scikit-learn, `.pt` for PyTorch, `.h5` or `SavedModel` for TensorFlow, ONNX, PMML).\n",
        "   - Any necessary preprocessing components (e.g., `StandardScaler`, `CountVectorizer`, `tokenizer` objects).\n",
        "   - Post processing logic.\n",
        "\n",
        "2. Metadata:\n",
        "   - **Model Name:** A human readable name (e.g., Customer Churn Predictor, Fraud Detection v2)\n",
        "   - **Version Number:** Automatically assigned or manually specified (e.g., `v1`, `v2.1`).\n",
        "   - **Description:** A brief summary of what the model does, its intended use and limitations.\n",
        "   - **Author/Owner:** Who trained and registered the model.\n",
        "   - **Timestamp:** Date and time of registration.\n",
        "   - **Link to Training Run/Experiment:** A pointer back to the specific experiment that generated this model (e.g., MLflow Run ID, W&B Run URL).\n",
        "\n",
        "3. Performance Metrics:\n",
        "   - Key evaluation metrics (e.g., F1 score, AUC, RMSE) achieved on the validation/test set during training. This allows for quick comparison.  \n",
        "\n",
        "4. Parameters:\n",
        "   - The hyperparameters used to train this specific model version.\n",
        "\n",
        "5. Dependencies: \n",
        "   - List of libraries and their versions required to load and run he model (e.g. `requirement.txt`, Conda environment file).\n",
        "\n",
        "6. Schema (input/Output): \n",
        "   - Expected input schema (feature names, data types) and output schema (prediction format).  This is crucial for ensuring compatibility with deployment environments.          \n",
        "\n",
        "7. Usage/Deployment Information:\n",
        "   - Current stage of the model (e.g., Staging, Production, Archived).\n",
        "   - Links to where the model is currently deployed.\n",
        "\n",
        "8. Tags:\n",
        "   - Custom tags for categorization (e.g. `prod-ready`,`experiment`,`image-classification`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **How Model Registration fits into the MLOps Workflow:**\n",
        "\n",
        "1. **Experimentation & Development:** Data Scientist train many models and track them using experiment tracking tools.\n",
        "\n",
        "2. **Model Selection:** Once a promising model is identified (based on performance metrics and business criteria form experiment tracking), its selected for potential deployment. \n",
        "\n",
        "3. **Registration:** The selected model, along with its metadata, artifacts, and a link to its training run is registered in the model registry.  Its often initially marked as Staging or candidate.\n",
        "\n",
        "4. **Testing & Validation:** The registered model undergoes further testing (e.g., inference testing, A/B testing, bias checks) in a staging environment.\n",
        "\n",
        "5. **Promotion:** If it passes all tests, its promoted to Production within the registry. This signifies that its ready for live traffic.\n",
        "\n",
        "6. **Deployment** Deployment systems pull the production version of the model from the registry and deploy it to serving infrastructure.\n",
        "\n",
        "7. **Monitoring & Management:** performance in production is continuously monitored. If performance degrades, a new model version might be trained, registered, a promoted, initiating a new cycle.  If a model is no longer used, it might be archived. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Tools for Model Registration**\n",
        "\n",
        "Most MLOps platforms and cloud ML serves offer integrated model registries:\n",
        "\n",
        "- **MLflow Model Registry:** Part of the open source MLflow ecosystem, widely used for managing model versions, stages, and metadata.\n",
        "- **AWS SageMaker Model Registry:** A managed service within Amazon Sagemaker for versioning, storing, and deploying models. \n",
        "- **Google Cloud Vertex AI Model Registry:** Google's centralized repository for managing ML models and their versions. \n",
        "- **Azure Machine Learning Model Registry:** Microsoft's offering for managing and tracking models.\n",
        "- **Hugging Face Hub:** While primarily for sharing pre trained models, it also serves as a registry for fine tuned models for NLP/Vision.\n",
        "- **Databricks Unity Catalog:** Combines data governance with model governance on the Databricks platform.\n",
        "- **Custom Solutions:** For organizations with vary specific needs, custom model registries can be built, often leveraging existing data storage and metadata management tools. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model registration is a cornerstone of MLOps, transforming the chaotic process of model development into a structured, reproducible, and governable workflow, essential for reliably deploying the managing AI in production. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_batch_prediction.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
