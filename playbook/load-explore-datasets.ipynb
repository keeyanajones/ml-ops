{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Loading and Exploring Datasets**\n",
        "\n",
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Keeyana Jones](https://github.com/keeyanajones/) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Overview**\n",
        "\n",
        "Loading and exploring datasets are the crucial first steps in any data science, machine learning, or data analysis project.  Its where you get to know your data, understand its structure, identify potential issues, and begin to form hypotheses. Think of it as interviewing your data before you start working with it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Loading Datasets**\n",
        "\n",
        "Loading refers to the process of bringing data from its storage location (a file, a database, a web API, etc,) into your analytical environment (like a Python script, R console, or data analysis software) where you can manipulate it.\n",
        "\n",
        "#### **Common Data Formats and How to Load Them (using Python with Pandas as an example):**\n",
        "- **CSV (Common Separated Values):** One of the most common formats, simple plain text files where columns are separated by commas (or other delimiters like tabs for TSV)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "df = pd.read_csv('my_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Excel Files (.xls, .xlsx):**\n",
        "Spreadsheets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_excel('my_data.xlsx')\n",
        "# if there are multiple sheets, you might specify sheet_name\n",
        "# df = pd.read_excel('my_data.xlsx', sheet_name='Sheet1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **JSON (JavaScript Object Notation):** A human readable data interchange format, often used for web APIs.  Can be nested."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_json('my_data.json')\n",
        "# for more complex/nested JSON, you might need to use json_normalize\n",
        "# from pandas.io.json import json_normalize\n",
        "# with open('nested_data.json') as f:\n",
        "#   data = json.load(f)\n",
        "# df = json_normalize(data['records'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **SQL Databases:** Data stored in relational databases (MySQL, PostgreSQL, SQL Server, SQLite, etc). You'll need a database connector library (e.g., `sqlalchemy` for Python)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "engine = create_engine('sqlite:///my_database.db') # Example for SQLite\n",
        "# df = pd.read_sql_table('my_table', engine) # for entire table\n",
        "df = pd.read_sql_query('SELECT * FROM my_table WHERE condition = \"value\"', engine) # For specific query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Parquet, Feather, HDFS:** Binary, columnar storage formats optimized for fast reads and writes especially for large datasets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_parquet('my_data.parquet')\n",
        "df = pd.read_feather('my_data.feather')\n",
        "df = pd.read_hdf('my_data.h5', key='df') # HDF5 can store multiple objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Pickle:** Python specific binary format for serializing Python objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_pickle('my_data.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **API (Application Programming Interfaces):** Fetching data directly from web services. This typically involves using a library like `requests` and then parsing the JSON/XML response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "response = requests.get('https://api.example.com/data')\n",
        "data = response.json()\n",
        "df = pd.DataFrame(data['results']) # or custom parsing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Cloud Storage (S3, GCS, Azure Blob Storage):** Data stored in cloud object storage. Pandas (and other libraries) often have direct support or you might need to use cloud specific SDKs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for S3, you might need boto3 and s3fs installed\n",
        "# df = pd.read_csv('s3://my-bucket/my_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Exploring Datasets (Exploratory Data Analysis - EDA):**\n",
        "\n",
        "Once loaded, the real work begins:\n",
        "Understanding you data. EDA is a critical process for:\n",
        "- **Understand Data Structure:** What ae the columns? What data types do they have?\n",
        "- **Identifying Data Quality Issues:** Missing values, duplicates, outliers, inconsistencies, incorrect data types.\n",
        "- **Discovering Patterns and Relationships:** How do variables relate to each other? Are there trends, correlations?\n",
        "- **Validating Assumptions:** Does the data reflect what you expect based on domain knowledge?\n",
        "- **Formulating Hypotheses:** Generate ideas about the underlying processes that generated the data.\n",
        "- **Informing Feature Engineering:** Identify variables that might need transformation or combination.\n",
        "- **Guiding Model Selection:** Some data characteristics might suggest certain model types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Key Techniques for Data Exploration:**\n",
        "\n",
        "A. Initial Overview:\n",
        "- `df.head()`/`df.tail()`: View the fist/last few rows to get a quick sense of the data.\n",
        "- `df.shape`: Get the number of rows and columns.\n",
        "- `df.columns`: List all column names.\n",
        "- `df.info()`: Get a concise summary including column names, non-null counts, and data types (Dtypes). Essential for quickly spotting missing data and incorrect types.\n",
        "- `df.types`: Get the data type of each column.\n",
        "- `df.describe()`: Generate descriptive statistics (count, mean, std, min, max, quartiles) for numerical columns.\n",
        "- `df.isnull().sum()`: Count missing values per column.\n",
        "- `df.isnull().sum().sum()`: for total missing.\n",
        "- `df.duplicated().sum()`: Count duplicate rows.\n",
        "- `df.drop_duplicates()`: to remove duplicates.\n",
        "\n",
        "B. Understanding individual Variables (Univariate Analysis):\n",
        "- Numerical Variables:\n",
        "   - **Histograms:** Show the distribution of values.`df['column'].hist()`\n",
        "   - **Box Plots:** Show central tendency, spread, and outliers. `df.boxplot(column='column')`   \n",
        "   - **Density Plots (KDE):** Smooth version of a histogram. `df['column'].plot(kind='kind')`   \n",
        "   - **Value Counts:** For discrete numerical data (e.g., `df['age'].value_counts()`).   \n",
        "   - **Unique Values:** `df['column'].nunique()` to count unique values, `df['column'].unique()` to list unique values.\n",
        "\n",
        "- Categorical Variables:\n",
        "   - `df['column'].value_counts()`: Count occurrences of each unique category.\n",
        "   - **Bar Charts:** Visualize the frequency or proportion of each category. `df['column'].value_counts().plot(kind='bar')`\n",
        "   - **Pie Charts:** For proportions (use with caution for many categories).\n",
        "\n",
        "C. Understanding Relationships Between Variables (Bivariate/Multivariate Analysis):\n",
        "- Numerical vs. Numerical:\n",
        "   - **Scatter Plots:** Show relationship between two numerical variables. `df.plot(kind='scatter', x='col1', y='col2')`\n",
        "   - **Correlation Matrix/Heatmap:** Quantify linear relationships between numerical variables. `df.corr()` and `sns.heatmap(df.corr(), annot=true)` (using Seaborn).\n",
        "\n",
        "- Categorical vs. Numerical:\n",
        "   - **Box Plots/Violin Plots:** Compare the distribution of a numerical variable across different categories. `sns.boxplot(x='category_col', y='numerical_col', data=df)`\n",
        "   - **Bar Plots (Grouped/Stacked):** Show average numerical value per category.\n",
        "\n",
        "- Categorical vs. Categorical:\n",
        "   - **Crosstabulations:** Frequency tables showing counts for combinations of categories. `pd.crosstab(df['cat_col1'], df['cat_col2'])`\n",
        "   - **Stacked Bar Charts:** Visualize proportions of one category within another.\n",
        "\n",
        "D. Advanced Exploration (often involving visualization libraries):\n",
        "   - **Seaborn and Matplotlib (Python):** Widely used for creating rich statistical plots.\n",
        "   - **Plotly/Bokeh/Altair (Python):** Fore interactive visualizations.\n",
        "   - **Geospatial Plots:** If you have geographical data.\n",
        "   - **Time Series Plots:** For data with a temporal component.\n",
        "   - **Pair plots:** Create scatter plots for all pairs of numerical variables (and histograms for individual variables) in a dataset. `sns.pairplot(df)`\n",
        "   - **Clustering (Exploratory):** Sometimes, running a simple clustering algorithm can help reveal nattural groupings in the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Tools and Libraries:**\n",
        "\n",
        "- **Pandas (Python):** The defacto standard for data manipulation and analysis in Python.\n",
        "- **NumPy (Python):** Underpins Pandas, great for numerical operations. \n",
        "- **Matplotlib (Python):** Core plotting library.\n",
        "- **Seaborn (Python):** Built on Matplotlib, provides a higher level interface for statistical graphics.\n",
        "- **Scikit-learn (Python):** Offers tools for data preprocessing, scaling, and basic modeling.\n",
        "- **Jupyter Notebooks/Labs or VS Code:** Interactive environments ideal for EDA, allowing you to mix code, output, and explanatory text.\n",
        "- **R (with Tidyverse, ggplot2):** A powerful alternative ecosystem for statistical analysis and visualization.\n",
        "- **SQL:** For querying and exploring data directly in databases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By thoroughly loading and exploring your datasets, you lay a strong foundation for the subsequent steps of cleaning, preprocessing, feature engineering, model building, and evaluation, ultimately leading to more robust and insightful analyses or machine learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_batch_prediction.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
